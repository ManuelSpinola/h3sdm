[{"path":"https://manuelspinola.github.io/h3sdm/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2025 Manuel Spinola Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/articles/h3sdm.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"h3sdm workflow for a single model","text":"tutorial demonstrates complete workflow species distribution modeling (SDM) single species using h3sdm related packages. cover data preparation, model fitting, spatial cross-validation, prediction, feature importance analysis. Note: h3sdm package depends paisaje package data access processing functions. paisaje available CRAN, must installed GitHub using:","code":"install.packages(\"remotes\") remotes::install_github(\"ManuelSpinola/paisaje\") # Load the required packages library(h3sdm) library(paisaje) library(tidyverse) library(here) library(tidymodels) library(spatialsample) library(sf) library(terra) library(tidyterra) library(DALEX) library(DALEXtra) library(ingredients) library(exactextractr) library(workflowsets) library(themis) library(ggbrick)  # Optional packages for advanced modeling or visualization: if (requireNamespace(\"ranger\", quietly = TRUE)) library(ranger) if (requireNamespace(\"xgboost\", quietly = TRUE)) library(xgboost)"},{"path":"https://manuelspinola.github.io/h3sdm/articles/h3sdm.html","id":"define-the-area-of-interest","dir":"Articles","previous_headings":"","what":"1. Define the Area of Interest","title":"h3sdm workflow for a single model","text":"start defining geographical area modeling. use Costa Rica example. file includesd ‘h3sdm’ package.","code":"cr <- cr_outline_c"},{"path":"https://manuelspinola.github.io/h3sdm/articles/h3sdm.html","id":"load-environmental-predictors","dir":"Articles","previous_headings":"","what":"2. Load Environmental Predictors","title":"h3sdm workflow for a single model","text":"use WorldClim historic bioclimatic variables Costa Rica environmental predictors. data included ‘h3sdm’ package.","code":"bio <- terra::rast(system.file(\"extdata\", \"bioclim_current.tif\", package = \"h3sdm\")) names(bio) <- gsub(\".*bio_\", \"bio\", names(bio))"},{"path":"https://manuelspinola.github.io/h3sdm/articles/h3sdm.html","id":"load-species-occurrence-data","dir":"Articles","previous_headings":"","what":"3. Load Species Occurrence Data","title":"h3sdm workflow for a single model","text":"obtain presence–absence data species interest (Silverstoneia flotator). use h3sdm_pa function generate presence pseudo-absence records. limit 10,000 records set ensure presence records retrieved, 300 pseudo-absences generated. different methods generating pseudo-absences; , rely random sampling. Since approximately 100 positive hexagons resolution 7, request three times number (.e., 300) pseudo-absences. resolution, H3 hexagons 5.16 ha size. parameters can adjusted depending specific needs characteristics species modeled.","code":"records <- h3sdm_pa(\"Silverstoneia flotator\", cr, res = 7, limit = 10000, n_pseudoabs = 300) head(records) #> Simple feature collection with 6 features and 2 fields #> Geometry type: MULTIPOLYGON #> Dimension:     XY #> Bounding box:  xmin: -84.06344 ymin: 8.486587 xmax: -82.77295 ymax: 9.643344 #> Geodetic CRS:  WGS 84 #>          h3_address presence                       geometry #> 43  8766b4415ffffff        1 MULTIPOLYGON (((-84.05549 9... #> 165 87679b636ffffff        1 MULTIPOLYGON (((-82.79149 9... #> 198 8766b54d3ffffff        1 MULTIPOLYGON (((-83.18895 8... #> 427 87679b78effffff        1 MULTIPOLYGON (((-82.85228 9... #> 796 8766b0135ffffff        1 MULTIPOLYGON (((-83.71366 8... #> 893 8766b014cffffff        1 MULTIPOLYGON (((-83.53362 8... table(records$presence) #>  #>   0   1  #> 300 114"},{"path":"https://manuelspinola.github.io/h3sdm/articles/h3sdm.html","id":"prepare-predictors","dir":"Articles","previous_headings":"","what":"4. Prepare Predictors","title":"h3sdm workflow for a single model","text":"Prepare environmental predictors extracting values hexagon study area.  case select bio1 (Annual Mean Temperature), bio12 (Annual Precipitation), bio15 (Precipitation Seasonality). can visualize one predictors, example Bio1.","code":"h7 <- h3sdm_get_grid(cr, res = 7) ggplot() +   geom_sf(data = h7) bio_predictors <- h3sdm_extract_num(bio, h7) #>   |                                                                     |                                                             |   0%  |                                                                     |                                                             |   1%  |                                                                     |=                                                            |   1%  |                                                                     |=                                                            |   2%  |                                                                     |==                                                           |   2%  |                                                                     |==                                                           |   3%  |                                                                     |==                                                           |   4%  |                                                                     |===                                                          |   4%  |                                                                     |===                                                          |   5%  |                                                                     |===                                                          |   6%  |                                                                     |====                                                         |   6%  |                                                                     |====                                                         |   7%  |                                                                     |=====                                                        |   7%  |                                                                     |=====                                                        |   8%  |                                                                     |=====                                                        |   9%  |                                                                     |======                                                       |   9%  |                                                                     |======                                                       |  10%  |                                                                     |======                                                       |  11%  |                                                                     |=======                                                      |  11%  |                                                                     |=======                                                      |  12%  |                                                                     |========                                                     |  12%  |                                                                     |========                                                     |  13%  |                                                                     |========                                                     |  14%  |                                                                     |=========                                                    |  14%  |                                                                     |=========                                                    |  15%  |                                                                     |=========                                                    |  16%  |                                                                     |==========                                                   |  16%  |                                                                     |==========                                                   |  17%  |                                                                     |===========                                                  |  17%  |                                                                     |===========                                                  |  18%  |                                                                     |===========                                                  |  19%  |                                                                     |============                                                 |  19%  |                                                                     |============                                                 |  20%  |                                                                     |=============                                                |  20%  |                                                                     |=============                                                |  21%  |                                                                     |=============                                                |  22%  |                                                                     |==============                                               |  22%  |                                                                     |==============                                               |  23%  |                                                                     |==============                                               |  24%  |                                                                     |===============                                              |  24%  |                                                                     |===============                                              |  25%  |                                                                     |================                                             |  25%  |                                                                     |================                                             |  26%  |                                                                     |================                                             |  27%  |                                                                     |=================                                            |  27%  |                                                                     |=================                                            |  28%  |                                                                     |=================                                            |  29%  |                                                                     |==================                                           |  29%  |                                                                     |==================                                           |  30%  |                                                                     |===================                                          |  30%  |                                                                     |===================                                          |  31%  |                                                                     |===================                                          |  32%  |                                                                     |====================                                         |  32%  |                                                                     |====================                                         |  33%  |                                                                     |====================                                         |  34%  |                                                                     |=====================                                        |  34%  |                                                                     |=====================                                        |  35%  |                                                                     |======================                                       |  35%  |                                                                     |======================                                       |  36%  |                                                                     |======================                                       |  37%  |                                                                     |=======================                                      |  37%  |                                                                     |=======================                                      |  38%  |                                                                     |=======================                                      |  39%  |                                                                     |========================                                     |  39%  |                                                                     |========================                                     |  40%  |                                                                     |=========================                                    |  40%  |                                                                     |=========================                                    |  41%  |                                                                     |=========================                                    |  42%  |                                                                     |==========================                                   |  42%  |                                                                     |==========================                                   |  43%  |                                                                     |===========================                                  |  43%  |                                                                     |===========================                                  |  44%  |                                                                     |===========================                                  |  45%  |                                                                     |============================                                 |  45%  |                                                                     |============================                                 |  46%  |                                                                     |============================                                 |  47%  |                                                                     |=============================                                |  47%  |                                                                     |=============================                                |  48%  |                                                                     |==============================                               |  48%  |                                                                     |==============================                               |  49%  |                                                                     |==============================                               |  50%  |                                                                     |===============================                              |  50%  |                                                                     |===============================                              |  51%  |                                                                     |===============================                              |  52%  |                                                                     |================================                             |  52%  |                                                                     |================================                             |  53%  |                                                                     |=================================                            |  53%  |                                                                     |=================================                            |  54%  |                                                                     |=================================                            |  55%  |                                                                     |==================================                           |  55%  |                                                                     |==================================                           |  56%  |                                                                     |==================================                           |  57%  |                                                                     |===================================                          |  57%  |                                                                     |===================================                          |  58%  |                                                                     |====================================                         |  58%  |                                                                     |====================================                         |  59%  |                                                                     |====================================                         |  60%  |                                                                     |=====================================                        |  60%  |                                                                     |=====================================                        |  61%  |                                                                     |======================================                       |  61%  |                                                                     |======================================                       |  62%  |                                                                     |======================================                       |  63%  |                                                                     |=======================================                      |  63%  |                                                                     |=======================================                      |  64%  |                                                                     |=======================================                      |  65%  |                                                                     |========================================                     |  65%  |                                                                     |========================================                     |  66%  |                                                                     |=========================================                    |  66%  |                                                                     |=========================================                    |  67%  |                                                                     |=========================================                    |  68%  |                                                                     |==========================================                   |  68%  |                                                                     |==========================================                   |  69%  |                                                                     |==========================================                   |  70%  |                                                                     |===========================================                  |  70%  |                                                                     |===========================================                  |  71%  |                                                                     |============================================                 |  71%  |                                                                     |============================================                 |  72%  |                                                                     |============================================                 |  73%  |                                                                     |=============================================                |  73%  |                                                                     |=============================================                |  74%  |                                                                     |=============================================                |  75%  |                                                                     |==============================================               |  75%  |                                                                     |==============================================               |  76%  |                                                                     |===============================================              |  76%  |                                                                     |===============================================              |  77%  |                                                                     |===============================================              |  78%  |                                                                     |================================================             |  78%  |                                                                     |================================================             |  79%  |                                                                     |================================================             |  80%  |                                                                     |=================================================            |  80%  |                                                                     |=================================================            |  81%  |                                                                     |==================================================           |  81%  |                                                                     |==================================================           |  82%  |                                                                     |==================================================           |  83%  |                                                                     |===================================================          |  83%  |                                                                     |===================================================          |  84%  |                                                                     |====================================================         |  84%  |                                                                     |====================================================         |  85%  |                                                                     |====================================================         |  86%  |                                                                     |=====================================================        |  86%  |                                                                     |=====================================================        |  87%  |                                                                     |=====================================================        |  88%  |                                                                     |======================================================       |  88%  |                                                                     |======================================================       |  89%  |                                                                     |=======================================================      |  89%  |                                                                     |=======================================================      |  90%  |                                                                     |=======================================================      |  91%  |                                                                     |========================================================     |  91%  |                                                                     |========================================================     |  92%  |                                                                     |========================================================     |  93%  |                                                                     |=========================================================    |  93%  |                                                                     |=========================================================    |  94%  |                                                                     |==========================================================   |  94%  |                                                                     |==========================================================   |  95%  |                                                                     |==========================================================   |  96%  |                                                                     |===========================================================  |  96%  |                                                                     |===========================================================  |  97%  |                                                                     |===========================================================  |  98%  |                                                                     |============================================================ |  98%  |                                                                     |============================================================ |  99%  |                                                                     |=============================================================|  99%  |                                                                     |=============================================================| 100% predictors <- h3sdm_predictors(bio_predictors) predictors <- predictors |>   dplyr::select(h3_address, bio1, bio12, bio15, geometry)"},{"path":"https://manuelspinola.github.io/h3sdm/articles/h3sdm.html","id":"combine-records-and-predictors","dir":"Articles","previous_headings":"","what":"5. Combine Records and Predictors","title":"h3sdm workflow for a single model","text":"Merge species occurrence records environmental predictors.","code":"dat <- h3sdm_data(records, predictors)"},{"path":"https://manuelspinola.github.io/h3sdm/articles/h3sdm.html","id":"spatial-cross-validation","dir":"Articles","previous_headings":"","what":"6. Spatial Cross-Validation","title":"h3sdm workflow for a single model","text":"Define spatial blocks cross-validation account spatial autocorrelation. Plot spatial blocks.","code":"scv <- h3sdm_spatial_cv(dat, v = 5, repeats = 1)"},{"path":"https://manuelspinola.github.io/h3sdm/articles/h3sdm.html","id":"define-recipe-and-model","dir":"Articles","previous_headings":"","what":"7. Define Recipe and Model","title":"h3sdm workflow for a single model","text":"Create modeling recipe specify classification model. start presence–absence data aggregated hexagonal cells. initial data, obtained roughly 100 hexagons presence (presence = 1). pseudo-absences, sampled three times absence hexagons (presence = 0) ensure sufficient coverage. results imbalanced dataset, can bias model toward predicting absences. correct , use step_downsample(presence) themis package. Key points: majority class (pseudo-absence hexagons) reduced. minority class (presence hexagons) remains unchanged. -sampling, dataset balanced, improving model training evaluation. case, -sampling ensures 100 presence hexagons comparable number pseudo-absence hexagons used modeling, preventing bias toward absences retaining full presence information. Now define logistic regression model using parsnip package, tidymodels framework.","code":"receta <- h3sdm_recipe(dat) |>   themis::step_downsample(presence) modelo <- parsnip::logistic_reg() %>%   parsnip::set_engine(\"glm\") %>%   parsnip::set_mode(\"classification\")"},{"path":"https://manuelspinola.github.io/h3sdm/articles/h3sdm.html","id":"create-workflow","dir":"Articles","previous_headings":"","what":"8. Create Workflow","title":"h3sdm workflow for a single model","text":"Create workflow combining recipe model.","code":"wf <- h3sdm_workflow(modelo, receta)"},{"path":"https://manuelspinola.github.io/h3sdm/articles/h3sdm.html","id":"fit-the-model","dir":"Articles","previous_headings":"","what":"9. Fit the Model","title":"h3sdm workflow for a single model","text":"fitting model, need extract presence data dataset. ensures metrics, cross-validation, evaluation focus correctly locations species actually present. Next, fit model using spatial cross-validation scheme. Spatial CV accounts spatial autocorrelation partitioning data spatially distinct folds, providing realistic assessment model performance compared random CV. Key points: presence_data contains hexagons presence = 1. cross-validation folds spatially blocked reduce leakage training test data. model trained validated using folds, ensuring robust performance evaluation.","code":"presence_data <- dat %>%   dplyr::filter(presence == 1) f <- h3sdm_fit_model(wf, scv, presence_data)"},{"path":"https://manuelspinola.github.io/h3sdm/articles/h3sdm.html","id":"evaluate-model-performance","dir":"Articles","previous_headings":"","what":"10. Evaluate Model Performance","title":"h3sdm workflow for a single model","text":"fitting model, assess performance using cross-validated metrics ROC-AUC, accuracy, TSS, Boyce index. h3sdm_eval_metrics() function computes metrics based fitted model presence data, providing quantitative measure well model distinguishes presence absence across spatial folds. Key points: Metrics computed using spatial cross-validation, results reflect realistic predictive performance. ROC-AUC evaluates discrimination ability; TSS balances sensitivity specificity. Boyce index evaluates well predicted suitability matches observed presences, particularly useful presence-pseudo-absence data. metrics help identify whether model reliably predicts species occurrence. can visualize metrics.","code":"evaluation_metrics <- h3sdm_eval_metrics(   fitted_model  = f$cv_model,   presence_data = presence_data ) evaluation_metrics #> # A tibble: 8 × 6 #>   .metric  .estimator  mean std_err conf_low conf_high #>   <chr>    <chr>      <dbl>   <dbl>    <dbl>     <dbl> #> 1 accuracy binary     0.673  0.0489   0.577      0.768 #> 2 f_meas   binary     0.743  0.0420   0.660      0.825 #> 3 kap      binary     0.292  0.101    0.0934     0.490 #> 4 roc_auc  binary     0.685  0.0734   0.541      0.828 #> 5 sens     binary     0.650  0.0601   0.532      0.768 #> 6 spec     binary     0.696  0.121    0.459      0.933 #> 7 tss      binary     0.478 NA       NA         NA     #> 8 boyce    binary     0.666 NA       NA         NA ggplot(evaluation_metrics, aes(.metric, mean)) +   theme_minimal() +   geom_col(width = 0.03, color = \"dodgerblue3\", fill = \"dodgerblue3\") +   geom_point(size = 3, color = \"orange\") +   ylim(0,1)"},{"path":"https://manuelspinola.github.io/h3sdm/articles/h3sdm.html","id":"make-predictions","dir":"Articles","previous_headings":"","what":"11. Make Predictions","title":"h3sdm workflow for a single model","text":"Generate spatial predictions species distribution across study area.","code":"p <- h3sdm_predict(f, predictors)"},{"path":"https://manuelspinola.github.io/h3sdm/articles/h3sdm.html","id":"map","dir":"Articles","previous_headings":"","what":"12. Map","title":"h3sdm workflow for a single model","text":"Now can visualize predictions map.  map represents habitat suitability species across hexagons. values (usually 0 1 logistic model) indicate habitat suitability hexagon species. Interpretation prediction values: Higher values → suitable habitat Lower values → less suitable habitat","code":""},{"path":"https://manuelspinola.github.io/h3sdm/articles/h3sdm.html","id":"model-interpretation-feature-importance-partial-dependence","dir":"Articles","previous_headings":"","what":"13. Model Interpretation: Feature Importance & Partial Dependence","title":"h3sdm workflow for a single model","text":"Finallly, interpret model understand predictors influential affect predictions. First create explainer object using DALEX package.","code":"e <- h3sdm_explain(f$final_model, data = dat) #> Preparation of a new explainer is initiated #>   -> model label       :  h3sdm workflow  #>   -> data              :  414  rows  6  cols  #>   -> target variable   :  414  values  #>   -> predict function  :  custom_predict  #>   -> predicted values  :  No value for predict function target column. (  default  ) #>   -> model_info        :  package tidymodels , ver. 1.4.1 , task classification (  default  )  #>   -> predicted values  :  numerical, min =  0.001604346 , mean =  0.4662787 , max =  0.8956116   #>   -> residual function :  difference between y and yhat (  default  ) #>   -> residuals         :  numerical, min =  -0.8956116 , mean =  -0.1909164 , max =  0.8797704   #>   A new explainer has been created!"},{"path":"https://manuelspinola.github.io/h3sdm/articles/h3sdm.html","id":"feature-importance","dir":"Articles","previous_headings":"13. Model Interpretation: Feature Importance & Partial Dependence","what":"Feature Importance","title":"h3sdm workflow for a single model","text":"evaluate importance predictor variable using permutation importance. method assesses much model’s performance decreases values predictor randomly shuffled, indicating contribution model. need specify predictor variables evaluate, excluding non-predictor columns. Now compute variable importance. can visualize variable importance.","code":"predictors_to_evaluate <- setdiff(names(e$data), c(\"h3_address\", \"x\", \"y\", \"presence\")) var_imp <- model_parts(   explainer = e,   variables = predictors_to_evaluate ) plot(var_imp)"},{"path":"https://manuelspinola.github.io/h3sdm/articles/h3sdm.html","id":"partial-dependence-plots","dir":"Articles","previous_headings":"13. Model Interpretation: Feature Importance & Partial Dependence","what":"Partial Dependence Plots","title":"h3sdm workflow for a single model","text":"create partial dependence plots (PDPs) visualize relationship key predictors predicted habitat suitability. PDPs show predicted outcome changes single predictor varies, averaging effects predictors. Now can plot PDPs.  predictors show positive relationship habitat suitability, Bio12 (annual precipitation) Bio1 (mean annual temperature) stand higher importance stronger positive effects. contrast, Bio15 (precipitation seasonality) weaker positive effect, suggesting areas variable rainfall somewhat suitable, less influential Bio12 Bio1.","code":"pdp_glm <- partial_dependence(e, variables = c(\"bio12\", \"bio1\", \"bio15\")) plot(pdp_glm)"},{"path":"https://manuelspinola.github.io/h3sdm/articles/h3sdm.html","id":"categorize-habitat-suitability","dir":"Articles","previous_headings":"","what":"14. Categorize Habitat Suitability","title":"h3sdm workflow for a single model","text":"can categorize continuous habitat suitability predictions discrete classes easier interpretation. define five categories: “low”, “Low”, “Medium”, “High”, “high”. Now can visualize categorized habitat suitability map.  can also count number hexagons habitat suitability category. Now can create waffle plot visualize distribution habitat suitability categories.","code":"p <- p %>%   mutate(     habitat_cat = cut(       prediction,       breaks = c(0, 0.2, 0.4, 0.6, 0.8, 1),       labels = c(\"Very low\", \"Low\", \"Medium\", \"High\", \"Very high\"),       include.lowest = TRUE     )   ) ggplot() +   theme_minimal() +   geom_sf(data = p, aes(fill = habitat_cat)) +   scale_fill_viridis_d(name = \"Habitat \\ncategory\", option = \"B\", direction = -1, na.translate = FALSE) counts_current <- p |>   st_drop_geometry() |>   count(habitat_cat) |>   drop_na() |>   mutate(scenario = \"Present\") counts_current #>   habitat_cat    n scenario #> 1    Very low 2287  Present #> 2         Low 3295  Present #> 3      Medium 1554  Present #> 4        High 2542  Present #> 5   Very high  738  Present"},{"path":"https://manuelspinola.github.io/h3sdm/articles/h3sdm.html","id":"make-predictios-for-a-future-scenario","dir":"Articles","previous_headings":"","what":"15. Make predictios for a future scenario","title":"h3sdm workflow for a single model","text":"can also make predictions future climate scenarios. use WorldClim future bioclimatic variables Costa Rica environmental predictors. data included ‘h3sdm’ package. three variables included: Bio1 (Annual Mean Temperature), Bio12 (Annual Precipitation), Bio15 (Precipitation Seasonality). Rename layers raster match names used model. prepare future predictors extracting values hexagon study area. Now can make predictions future scenario. can visualize future predictions map.  can categorize continuous habitat suitability predictions discrete classes easier interpretation. define five categories: “low”, “Low”, “Medium”, “High”, “high”. Now can visualize categorized habitat suitability map.  can also count number hexagons habitat suitability category. Now can create waffle plot visualize distribution habitat suitability categories future scenario.  Now can create waffle plot visualize distribution habitat suitability categories present future scenarios.","code":"bio_future <- terra::rast(system.file(\"extdata\", \"bioclim_future.tif\", package = \"h3sdm\")) names(bio_future) <- c(\"bio1\", \"bio12\", \"bio15\") bio_future_predictors <- h3sdm_extract_num(bio_future, h7) #>   |                                                                     |                                                             |   0%  |                                                                     |                                                             |   1%  |                                                                     |=                                                            |   1%  |                                                                     |=                                                            |   2%  |                                                                     |==                                                           |   2%  |                                                                     |==                                                           |   3%  |                                                                     |==                                                           |   4%  |                                                                     |===                                                          |   4%  |                                                                     |===                                                          |   5%  |                                                                     |===                                                          |   6%  |                                                                     |====                                                         |   6%  |                                                                     |====                                                         |   7%  |                                                                     |=====                                                        |   7%  |                                                                     |=====                                                        |   8%  |                                                                     |=====                                                        |   9%  |                                                                     |======                                                       |   9%  |                                                                     |======                                                       |  10%  |                                                                     |======                                                       |  11%  |                                                                     |=======                                                      |  11%  |                                                                     |=======                                                      |  12%  |                                                                     |========                                                     |  12%  |                                                                     |========                                                     |  13%  |                                                                     |========                                                     |  14%  |                                                                     |=========                                                    |  14%  |                                                                     |=========                                                    |  15%  |                                                                     |=========                                                    |  16%  |                                                                     |==========                                                   |  16%  |                                                                     |==========                                                   |  17%  |                                                                     |===========                                                  |  17%  |                                                                     |===========                                                  |  18%  |                                                                     |===========                                                  |  19%  |                                                                     |============                                                 |  19%  |                                                                     |============                                                 |  20%  |                                                                     |=============                                                |  20%  |                                                                     |=============                                                |  21%  |                                                                     |=============                                                |  22%  |                                                                     |==============                                               |  22%  |                                                                     |==============                                               |  23%  |                                                                     |==============                                               |  24%  |                                                                     |===============                                              |  24%  |                                                                     |===============                                              |  25%  |                                                                     |================                                             |  25%  |                                                                     |================                                             |  26%  |                                                                     |================                                             |  27%  |                                                                     |=================                                            |  27%  |                                                                     |=================                                            |  28%  |                                                                     |=================                                            |  29%  |                                                                     |==================                                           |  29%  |                                                                     |==================                                           |  30%  |                                                                     |===================                                          |  30%  |                                                                     |===================                                          |  31%  |                                                                     |===================                                          |  32%  |                                                                     |====================                                         |  32%  |                                                                     |====================                                         |  33%  |                                                                     |====================                                         |  34%  |                                                                     |=====================                                        |  34%  |                                                                     |=====================                                        |  35%  |                                                                     |======================                                       |  35%  |                                                                     |======================                                       |  36%  |                                                                     |======================                                       |  37%  |                                                                     |=======================                                      |  37%  |                                                                     |=======================                                      |  38%  |                                                                     |=======================                                      |  39%  |                                                                     |========================                                     |  39%  |                                                                     |========================                                     |  40%  |                                                                     |=========================                                    |  40%  |                                                                     |=========================                                    |  41%  |                                                                     |=========================                                    |  42%  |                                                                     |==========================                                   |  42%  |                                                                     |==========================                                   |  43%  |                                                                     |===========================                                  |  43%  |                                                                     |===========================                                  |  44%  |                                                                     |===========================                                  |  45%  |                                                                     |============================                                 |  45%  |                                                                     |============================                                 |  46%  |                                                                     |============================                                 |  47%  |                                                                     |=============================                                |  47%  |                                                                     |=============================                                |  48%  |                                                                     |==============================                               |  48%  |                                                                     |==============================                               |  49%  |                                                                     |==============================                               |  50%  |                                                                     |===============================                              |  50%  |                                                                     |===============================                              |  51%  |                                                                     |===============================                              |  52%  |                                                                     |================================                             |  52%  |                                                                     |================================                             |  53%  |                                                                     |=================================                            |  53%  |                                                                     |=================================                            |  54%  |                                                                     |=================================                            |  55%  |                                                                     |==================================                           |  55%  |                                                                     |==================================                           |  56%  |                                                                     |==================================                           |  57%  |                                                                     |===================================                          |  57%  |                                                                     |===================================                          |  58%  |                                                                     |====================================                         |  58%  |                                                                     |====================================                         |  59%  |                                                                     |====================================                         |  60%  |                                                                     |=====================================                        |  60%  |                                                                     |=====================================                        |  61%  |                                                                     |======================================                       |  61%  |                                                                     |======================================                       |  62%  |                                                                     |======================================                       |  63%  |                                                                     |=======================================                      |  63%  |                                                                     |=======================================                      |  64%  |                                                                     |=======================================                      |  65%  |                                                                     |========================================                     |  65%  |                                                                     |========================================                     |  66%  |                                                                     |=========================================                    |  66%  |                                                                     |=========================================                    |  67%  |                                                                     |=========================================                    |  68%  |                                                                     |==========================================                   |  68%  |                                                                     |==========================================                   |  69%  |                                                                     |==========================================                   |  70%  |                                                                     |===========================================                  |  70%  |                                                                     |===========================================                  |  71%  |                                                                     |============================================                 |  71%  |                                                                     |============================================                 |  72%  |                                                                     |============================================                 |  73%  |                                                                     |=============================================                |  73%  |                                                                     |=============================================                |  74%  |                                                                     |=============================================                |  75%  |                                                                     |==============================================               |  75%  |                                                                     |==============================================               |  76%  |                                                                     |===============================================              |  76%  |                                                                     |===============================================              |  77%  |                                                                     |===============================================              |  78%  |                                                                     |================================================             |  78%  |                                                                     |================================================             |  79%  |                                                                     |================================================             |  80%  |                                                                     |=================================================            |  80%  |                                                                     |=================================================            |  81%  |                                                                     |==================================================           |  81%  |                                                                     |==================================================           |  82%  |                                                                     |==================================================           |  83%  |                                                                     |===================================================          |  83%  |                                                                     |===================================================          |  84%  |                                                                     |====================================================         |  84%  |                                                                     |====================================================         |  85%  |                                                                     |====================================================         |  86%  |                                                                     |=====================================================        |  86%  |                                                                     |=====================================================        |  87%  |                                                                     |=====================================================        |  88%  |                                                                     |======================================================       |  88%  |                                                                     |======================================================       |  89%  |                                                                     |=======================================================      |  89%  |                                                                     |=======================================================      |  90%  |                                                                     |=======================================================      |  91%  |                                                                     |========================================================     |  91%  |                                                                     |========================================================     |  92%  |                                                                     |========================================================     |  93%  |                                                                     |=========================================================    |  93%  |                                                                     |=========================================================    |  94%  |                                                                     |==========================================================   |  94%  |                                                                     |==========================================================   |  95%  |                                                                     |==========================================================   |  96%  |                                                                     |===========================================================  |  96%  |                                                                     |===========================================================  |  97%  |                                                                     |===========================================================  |  98%  |                                                                     |============================================================ |  98%  |                                                                     |============================================================ |  99%  |                                                                     |=============================================================|  99%  |                                                                     |=============================================================| 100% predictors_future <- h3sdm_predictors(bio_future_predictors) p_future <- h3sdm_predict(f, predictors_future) p_future <- p_future %>%   mutate(     habitat_cat = cut(       prediction,       breaks = c(0, 0.2, 0.4, 0.6, 0.8, 1),       labels = c(\"Very low\", \"Low\", \"Medium\", \"High\", \"Very high\"),       include.lowest = TRUE     )   ) ggplot() +   theme_minimal() +   geom_sf(data = p_future, aes(fill = habitat_cat)) +   scale_fill_viridis_d(name = \"Habitat \\ncategory\", option = \"B\", direction = -1, na.translate = FALSE) counts_future <- p_future |>   st_drop_geometry() |>   count(habitat_cat) |>   drop_na() |>   mutate(scenario = \"Future\") counts_future #>   habitat_cat    n scenario #> 1    Very low 2130   Future #> 2         Low 3393   Future #> 3      Medium 1519   Future #> 4        High 2563   Future #> 5   Very high  776   Future"},{"path":"https://manuelspinola.github.io/h3sdm/articles/h3sdm.html","id":"conclusions","dir":"Articles","previous_headings":"","what":"16. Conclusions","title":"h3sdm workflow for a single model","text":"tutorial demonstrated complete SDM workflow single model using h3sdm package. key steps included: Defining study area Loading preparing environmental predictors Fetching species occurrence data Building predictive model spatial cross-validation Evaluating performance making predictions Assessing variable importance Categorizing habitat suitability Making predictions future climate scenarios Comparing habitat suitability present future scenarios workflow demonstrates modeling single species using one model. can easily adapted handle multiple species complex modeling scenarios, illustrated Articles section.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/articles/multi_model_workflow.html","id":"define-the-area-of-interest","dir":"Articles","previous_headings":"","what":"1. Define the Area of Interest","title":"h3sdm workflow for multiple models","text":"start defining geographical area modeling. use Costa Rica example. file includesd ‘h3sdm’ package.","code":"cr <- cr_outline_c"},{"path":"https://manuelspinola.github.io/h3sdm/articles/multi_model_workflow.html","id":"load-environmental-predictors","dir":"Articles","previous_headings":"","what":"2. Load Environmental Predictors","title":"h3sdm workflow for multiple models","text":"use WorldClim historic bioclimatic variables Costa Rica environmental predictors. data included ‘h3sdm’ package.","code":"bio <- terra::rast(system.file(\"extdata\", \"bioclim_current.tif\", package = \"h3sdm\")) names(bio) <- gsub(\".*bio_\", \"bio\", names(bio))"},{"path":"https://manuelspinola.github.io/h3sdm/articles/multi_model_workflow.html","id":"load-species-occurrence-data","dir":"Articles","previous_headings":"","what":"3. Load Species Occurrence Data","title":"h3sdm workflow for multiple models","text":"obtain presence–absence data species interest (Silverstoneia flotator). use h3sdm_pa function generate presence pseudo-absence records. limit 10,000 records set ensure presence records retrieved, 300 pseudo-absences generated. different methods generating pseudo-absences; , rely random sampling. Since approximately 100 positive hexagons resolution 7, request three times number (.e., 300) pseudo-absences. resolution, H3 hexagons 5.16 ha size. parameters can adjusted depending specific needs characteristics species modeled.","code":"records <- h3sdm_pa(\"Silverstoneia flotator\", cr, res = 7, limit = 10000, n_pseudoabs = 300) head(records) #> Simple feature collection with 6 features and 2 fields #> Geometry type: MULTIPOLYGON #> Dimension:     XY #> Bounding box:  xmin: -84.06344 ymin: 8.486587 xmax: -82.77295 ymax: 9.643344 #> Geodetic CRS:  WGS 84 #>          h3_address presence                       geometry #> 43  8766b4415ffffff        1 MULTIPOLYGON (((-84.05549 9... #> 165 87679b636ffffff        1 MULTIPOLYGON (((-82.79149 9... #> 198 8766b54d3ffffff        1 MULTIPOLYGON (((-83.18895 8... #> 427 87679b78effffff        1 MULTIPOLYGON (((-82.85228 9... #> 796 8766b0135ffffff        1 MULTIPOLYGON (((-83.71366 8... #> 893 8766b014cffffff        1 MULTIPOLYGON (((-83.53362 8... table(records$presence) #>  #>   0   1  #> 300 114 ggplot() +   theme_minimal() +   geom_sf(data = records, aes(fill = presence))"},{"path":"https://manuelspinola.github.io/h3sdm/articles/multi_model_workflow.html","id":"prepare-predictors","dir":"Articles","previous_headings":"","what":"4. Prepare Predictors","title":"h3sdm workflow for multiple models","text":"Prepare environmental predictors extracting values hexagon study area. case prepare de bioclimatic variables. working resolutio 7 create grid resolution.  case select Bio1 (Annual Mean Temperature), Bio12 (Annual Precipitation), Bio15 (Precipitation Seasonality). can visualize one predictors, example Bio1.","code":"h7 <- h3sdm_get_grid(cr, res = 7) ggplot() +   geom_sf(data = h7) bio_predictors <- h3sdm_extract_num(bio, h7) #>   |                                                                     |                                                             |   0%  |                                                                     |                                                             |   1%  |                                                                     |=                                                            |   1%  |                                                                     |=                                                            |   2%  |                                                                     |==                                                           |   2%  |                                                                     |==                                                           |   3%  |                                                                     |==                                                           |   4%  |                                                                     |===                                                          |   4%  |                                                                     |===                                                          |   5%  |                                                                     |===                                                          |   6%  |                                                                     |====                                                         |   6%  |                                                                     |====                                                         |   7%  |                                                                     |=====                                                        |   7%  |                                                                     |=====                                                        |   8%  |                                                                     |=====                                                        |   9%  |                                                                     |======                                                       |   9%  |                                                                     |======                                                       |  10%  |                                                                     |======                                                       |  11%  |                                                                     |=======                                                      |  11%  |                                                                     |=======                                                      |  12%  |                                                                     |========                                                     |  12%  |                                                                     |========                                                     |  13%  |                                                                     |========                                                     |  14%  |                                                                     |=========                                                    |  14%  |                                                                     |=========                                                    |  15%  |                                                                     |=========                                                    |  16%  |                                                                     |==========                                                   |  16%  |                                                                     |==========                                                   |  17%  |                                                                     |===========                                                  |  17%  |                                                                     |===========                                                  |  18%  |                                                                     |===========                                                  |  19%  |                                                                     |============                                                 |  19%  |                                                                     |============                                                 |  20%  |                                                                     |=============                                                |  20%  |                                                                     |=============                                                |  21%  |                                                                     |=============                                                |  22%  |                                                                     |==============                                               |  22%  |                                                                     |==============                                               |  23%  |                                                                     |==============                                               |  24%  |                                                                     |===============                                              |  24%  |                                                                     |===============                                              |  25%  |                                                                     |================                                             |  25%  |                                                                     |================                                             |  26%  |                                                                     |================                                             |  27%  |                                                                     |=================                                            |  27%  |                                                                     |=================                                            |  28%  |                                                                     |=================                                            |  29%  |                                                                     |==================                                           |  29%  |                                                                     |==================                                           |  30%  |                                                                     |===================                                          |  30%  |                                                                     |===================                                          |  31%  |                                                                     |===================                                          |  32%  |                                                                     |====================                                         |  32%  |                                                                     |====================                                         |  33%  |                                                                     |====================                                         |  34%  |                                                                     |=====================                                        |  34%  |                                                                     |=====================                                        |  35%  |                                                                     |======================                                       |  35%  |                                                                     |======================                                       |  36%  |                                                                     |======================                                       |  37%  |                                                                     |=======================                                      |  37%  |                                                                     |=======================                                      |  38%  |                                                                     |=======================                                      |  39%  |                                                                     |========================                                     |  39%  |                                                                     |========================                                     |  40%  |                                                                     |=========================                                    |  40%  |                                                                     |=========================                                    |  41%  |                                                                     |=========================                                    |  42%  |                                                                     |==========================                                   |  42%  |                                                                     |==========================                                   |  43%  |                                                                     |===========================                                  |  43%  |                                                                     |===========================                                  |  44%  |                                                                     |===========================                                  |  45%  |                                                                     |============================                                 |  45%  |                                                                     |============================                                 |  46%  |                                                                     |============================                                 |  47%  |                                                                     |=============================                                |  47%  |                                                                     |=============================                                |  48%  |                                                                     |==============================                               |  48%  |                                                                     |==============================                               |  49%  |                                                                     |==============================                               |  50%  |                                                                     |===============================                              |  50%  |                                                                     |===============================                              |  51%  |                                                                     |===============================                              |  52%  |                                                                     |================================                             |  52%  |                                                                     |================================                             |  53%  |                                                                     |=================================                            |  53%  |                                                                     |=================================                            |  54%  |                                                                     |=================================                            |  55%  |                                                                     |==================================                           |  55%  |                                                                     |==================================                           |  56%  |                                                                     |==================================                           |  57%  |                                                                     |===================================                          |  57%  |                                                                     |===================================                          |  58%  |                                                                     |====================================                         |  58%  |                                                                     |====================================                         |  59%  |                                                                     |====================================                         |  60%  |                                                                     |=====================================                        |  60%  |                                                                     |=====================================                        |  61%  |                                                                     |======================================                       |  61%  |                                                                     |======================================                       |  62%  |                                                                     |======================================                       |  63%  |                                                                     |=======================================                      |  63%  |                                                                     |=======================================                      |  64%  |                                                                     |=======================================                      |  65%  |                                                                     |========================================                     |  65%  |                                                                     |========================================                     |  66%  |                                                                     |=========================================                    |  66%  |                                                                     |=========================================                    |  67%  |                                                                     |=========================================                    |  68%  |                                                                     |==========================================                   |  68%  |                                                                     |==========================================                   |  69%  |                                                                     |==========================================                   |  70%  |                                                                     |===========================================                  |  70%  |                                                                     |===========================================                  |  71%  |                                                                     |============================================                 |  71%  |                                                                     |============================================                 |  72%  |                                                                     |============================================                 |  73%  |                                                                     |=============================================                |  73%  |                                                                     |=============================================                |  74%  |                                                                     |=============================================                |  75%  |                                                                     |==============================================               |  75%  |                                                                     |==============================================               |  76%  |                                                                     |===============================================              |  76%  |                                                                     |===============================================              |  77%  |                                                                     |===============================================              |  78%  |                                                                     |================================================             |  78%  |                                                                     |================================================             |  79%  |                                                                     |================================================             |  80%  |                                                                     |=================================================            |  80%  |                                                                     |=================================================            |  81%  |                                                                     |==================================================           |  81%  |                                                                     |==================================================           |  82%  |                                                                     |==================================================           |  83%  |                                                                     |===================================================          |  83%  |                                                                     |===================================================          |  84%  |                                                                     |====================================================         |  84%  |                                                                     |====================================================         |  85%  |                                                                     |====================================================         |  86%  |                                                                     |=====================================================        |  86%  |                                                                     |=====================================================        |  87%  |                                                                     |=====================================================        |  88%  |                                                                     |======================================================       |  88%  |                                                                     |======================================================       |  89%  |                                                                     |=======================================================      |  89%  |                                                                     |=======================================================      |  90%  |                                                                     |=======================================================      |  91%  |                                                                     |========================================================     |  91%  |                                                                     |========================================================     |  92%  |                                                                     |========================================================     |  93%  |                                                                     |=========================================================    |  93%  |                                                                     |=========================================================    |  94%  |                                                                     |==========================================================   |  94%  |                                                                     |==========================================================   |  95%  |                                                                     |==========================================================   |  96%  |                                                                     |===========================================================  |  96%  |                                                                     |===========================================================  |  97%  |                                                                     |===========================================================  |  98%  |                                                                     |============================================================ |  98%  |                                                                     |============================================================ |  99%  |                                                                     |=============================================================|  99%  |                                                                     |=============================================================| 100% predictors <- h3sdm_predictors(bio_predictors) predictors <- predictors |>   dplyr::select(h3_address, bio1, bio12, bio15, geometry) ggplot() +   theme_minimal() +   geom_sf(data = predictors, aes(fill = bio1)) +   scale_fill_viridis_c(option = \"B\")"},{"path":"https://manuelspinola.github.io/h3sdm/articles/multi_model_workflow.html","id":"combine-records-and-predictors","dir":"Articles","previous_headings":"","what":"5. Combine Records and Predictors","title":"h3sdm workflow for multiple models","text":"Merge species occurrence records environmental predictors.","code":"dat <- h3sdm_data(records, predictors)"},{"path":"https://manuelspinola.github.io/h3sdm/articles/multi_model_workflow.html","id":"spatial-cross-validation","dir":"Articles","previous_headings":"","what":"6. Spatial Cross-Validation","title":"h3sdm workflow for multiple models","text":"Define spatial blocks cross-validation account spatial autocorrelation. Plot spatial blocks.","code":"scv <- h3sdm_spatial_cv(dat, v = 5, repeats = 1) autoplot(scv)"},{"path":"https://manuelspinola.github.io/h3sdm/articles/multi_model_workflow.html","id":"define-recipe-and-models-multiple-models","dir":"Articles","previous_headings":"","what":"7. Define Recipe and Models (multiple models)","title":"h3sdm workflow for multiple models","text":"Create modeling recipe specify classification model. start presence–absence data aggregated hexagonal cells. initial data, obtained roughly 100 hexagons presence (presence = 1). pseudo-absences, sampled three times absence hexagons (presence = 0) ensure sufficient coverage. results imbalanced dataset, can bias model toward predicting absences. correct , use step_downsample(presence) themis package. Key points: majority class (pseudo-absence hexagons) reduced. minority class (presence hexagons) remains unchanged. -sampling, dataset balanced, improving model training evaluation. case, -sampling ensures 100 presence hexagons comparable number pseudo-absence hexagons used modeling, preventing bias toward absences retaining full presence information. Now define one model using parsnip package, tidymodels framework.","code":"receta <- h3sdm_recipe(dat) |>   themis::step_downsample(presence) |>   step_dummy(all_nominal_predictors()) # Define your models using parsnip # Modelos con defaults mod_log <- logistic_reg() %>%   set_engine(\"glm\") %>%   set_mode(\"classification\")  mod_rf <- rand_forest() %>%   set_engine(\"ranger\") %>%   set_mode(\"classification\")  mod_xgb <- boost_tree() %>%        # usa defaults   set_engine(\"xgboost\") %>%   set_mode(\"classification\")  # Create a named list of the models my_models <- list(   reg_log = mod_log,   random_forest = mod_rf,   xgboost = mod_xgb )"},{"path":"https://manuelspinola.github.io/h3sdm/articles/multi_model_workflow.html","id":"create-workflows","dir":"Articles","previous_headings":"","what":"8. Create Workflows","title":"h3sdm workflow for multiple models","text":"","code":"wfs <- h3sdm_workflows(my_models, receta) wfs #> $reg_log #> ══ Workflow ═══════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: logistic_reg() #>  #> ── Preprocessor ─────────────────────────────────────────────────────── #> 2 Recipe Steps #>  #> • step_downsample() #> • step_dummy() #>  #> ── Model ────────────────────────────────────────────────────────────── #> Logistic Regression Model Specification (classification) #>  #> Computational engine: glm  #>  #>  #> $random_forest #> ══ Workflow ═══════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: rand_forest() #>  #> ── Preprocessor ─────────────────────────────────────────────────────── #> 2 Recipe Steps #>  #> • step_downsample() #> • step_dummy() #>  #> ── Model ────────────────────────────────────────────────────────────── #> Random Forest Model Specification (classification) #>  #> Computational engine: ranger  #>  #>  #> $xgboost #> ══ Workflow ═══════════════════════════════════════════════════════════ #> Preprocessor: Recipe #> Model: boost_tree() #>  #> ── Preprocessor ─────────────────────────────────────────────────────── #> 2 Recipe Steps #>  #> • step_downsample() #> • step_dummy() #>  #> ── Model ────────────────────────────────────────────────────────────── #> Boosted Tree Model Specification (classification) #>  #> Computational engine: xgboost"},{"path":"https://manuelspinola.github.io/h3sdm/articles/multi_model_workflow.html","id":"fit-the-models","dir":"Articles","previous_headings":"","what":"9. Fit the Models","title":"h3sdm workflow for multiple models","text":"fitting model, need extract presence data dataset. ensures metrics, cross-validation, evaluation focus correctly locations species actually present. Next, fit models using spatial cross-validation scheme. Spatial CV accounts spatial autocorrelation partitioning data spatially distinct folds, providing realistic assessment model performance compared random CV.","code":"presence_data <- dat %>%   dplyr::filter(presence == 1) several <- h3sdm_fit_models(wfs, scv, presence_data)"},{"path":"https://manuelspinola.github.io/h3sdm/articles/multi_model_workflow.html","id":"evaluate-and-compare-models","dir":"Articles","previous_headings":"","what":"10. Evaluate and Compare Models","title":"h3sdm workflow for multiple models","text":"ROC AUC (roc_auc) → evaluates model’s ability discriminate presence absence/pseudo-absence, regardless threshold. standard metric probabilistic classification. Maximum TSS (tss_max) → combines sensitivity specificity single threshold-dependent value, showing well model predicts presences absences simultaneously. Boyce index (boyce) → measures model’s ability predict species distribution continuously assesses whether areas higher predicted values coincide observed presences.","code":"compare <- h3sdm_compare_models(several) compare #> # A tibble: 9 × 7 #>   model         .metric .estimator  mean std_err conf_low conf_high #>   <chr>         <chr>   <chr>      <dbl>   <dbl>    <dbl>     <dbl> #> 1 random_forest boyce   binary     0.95  NA        NA        NA     #> 2 xgboost       boyce   binary     0.894 NA        NA        NA     #> 3 random_forest roc_auc binary     0.869  0.0171    0.835     0.902 #> 4 xgboost       roc_auc binary     0.840  0.0223    0.796     0.883 #> 5 reg_log       roc_auc binary     0.704  0.0742    0.558     0.849 #> 6 random_forest tss     binary     0.598 NA        NA        NA     #> 7 xgboost       tss     binary     0.563 NA        NA        NA     #> 8 reg_log       tss     binary     0.529 NA        NA        NA     #> 9 reg_log       boyce   binary     0.476 NA        NA        NA ggplot(compare, aes(.metric, mean)) +   geom_col(width = 0.03) +   geom_point(size = 2) +   facet_wrap(~model)"},{"path":"https://manuelspinola.github.io/h3sdm/articles/multi_model_workflow.html","id":"select-the-best-model-and-make-predictions","dir":"Articles","previous_headings":"","what":"11. Select the Best Model and make Predictions","title":"h3sdm workflow for multiple models","text":"","code":"p_rf <- h3sdm_predict(several$models$random_forest, predictors) p_rf #> Simple feature collection with 10417 features and 7 fields #> Geometry type: MULTIPOLYGON #> Dimension:     XY #> Bounding box:  xmin: -85.95025 ymin: 8.039627 xmax: -82.55232 ymax: 11.21976 #> Geodetic CRS:  WGS 84 #> First 10 features: #>         h3_address     bio1    bio12    bio15 #> 1  876d6854dffffff 26.61501 1632.814 94.14928 #> 2  876d6bb8effffff 26.62722 2215.888 92.49077 #> 3  87679b4f5ffffff 25.08632 3023.892 26.03154 #> 4  8766b5d82ffffff 13.71321 3982.812 37.47940 #> 5  8766b4528ffffff 15.85883 2214.000 75.75454 #> 6  876d68adaffffff 23.29059 2412.908 69.25448 #> 7  876d6d625ffffff 26.03058 3024.874 47.24875 #> 8  876d6878affffff 26.30600 1746.000 91.93986 #> 9  8766b4ab5ffffff 20.26178 2883.596 41.66865 #> 10 876d69c94ffffff 22.67291 2361.003 70.83282 #>                          geometry         x         y prediction #> 1  MULTIPOLYGON (((-85.61874 1... -85.61355 10.744993 0.00080000 #> 2  MULTIPOLYGON (((-85.2204 9.... -85.21517  9.805806 0.00080000 #> 3  MULTIPOLYGON (((-83.01133 9... -83.00602  9.806921 0.65965556 #> 4  MULTIPOLYGON (((-83.07362 9... -83.06830  9.295924 0.02011032 #> 5  MULTIPOLYGON (((-83.93635 9... -83.93107  9.638151 0.07423651 #> 6  MULTIPOLYGON (((-85.04019 1... -85.03497 10.579597 0.20093651 #> 7  MULTIPOLYGON (((-84.50184 1... -84.49660 10.874768 0.28577460 #> 8  MULTIPOLYGON (((-85.69967 1... -85.69448 10.433590 0.01610000 #> 9  MULTIPOLYGON (((-83.32541 9... -83.32010  9.539664 0.09241032 #> 10 MULTIPOLYGON (((-84.94068 1... -84.93545 10.420003 0.18591270"},{"path":"https://manuelspinola.github.io/h3sdm/articles/multi_model_workflow.html","id":"map","dir":"Articles","previous_headings":"","what":"12. Map","title":"h3sdm workflow for multiple models","text":"Now can visualize predictions map.  map represents habitat suitability species across hexagons. values (usually 0 1 logistic model) indicate habitat suitability hexagon species. Interpretation prediction values: Higher values → suitable habitat Lower values → less suitable habitat","code":"ggplot() +   theme_minimal() +   geom_sf(data = p_rf, aes(fill = prediction)) +   scale_fill_viridis_c(name = \"Habitat \\nsuitability\",option = \"B\", direction = -1)"},{"path":"https://manuelspinola.github.io/h3sdm/articles/multi_model_workflow.html","id":"model-interpretation-feature-importance-partial-dependence","dir":"Articles","previous_headings":"","what":"13. Model Interpretation: Feature Importance & Partial Dependence","title":"h3sdm workflow for multiple models","text":"Finallly, interpret model understand predictors influential affect predictions. First, extract fitted random forest model list models. create explainer object using DALEX package.","code":"rf_fitted <- several$models$random_forest$final_model e <- h3sdm_explain(rf_fitted, data = dat) #> Preparation of a new explainer is initiated #>   -> model label       :  h3sdm workflow  #>   -> data              :  414  rows  6  cols  #>   -> target variable   :  414  values  #>   -> predict function  :  custom_predict  #>   -> predicted values  :  No value for predict function target column. (  default  ) #>   -> model_info        :  package tidymodels , ver. 1.4.1 , task classification (  default  )  #>   -> predicted values  :  numerical, min =  4e-04 , mean =  0.3706201 , max =  0.9878635   #>   -> residual function :  difference between y and yhat (  default  ) #>   -> residuals         :  numerical, min =  -0.9798127 , mean =  -0.09525779 , max =  0.7162476   #>   A new explainer has been created!"},{"path":"https://manuelspinola.github.io/h3sdm/articles/multi_model_workflow.html","id":"feature-importance","dir":"Articles","previous_headings":"13. Model Interpretation: Feature Importance & Partial Dependence","what":"Feature Importance","title":"h3sdm workflow for multiple models","text":"evaluate importance predictor variable using permutation importance. method assesses much model’s performance decreases values predictor randomly shuffled, indicating contribution model. need specify predictor variables evaluate, excluding non-predictor columns. Now compute variable importance. can visualize variable importance.","code":"predictors_to_evaluate <- setdiff(names(e$data), c(\"h3_address\", \"x\", \"y\", \"presence\")) var_imp <- model_parts(   explainer = e,   variables = predictors_to_evaluate ) plot(var_imp)"},{"path":"https://manuelspinola.github.io/h3sdm/articles/multi_model_workflow.html","id":"partial-dependence-plots","dir":"Articles","previous_headings":"13. Model Interpretation: Feature Importance & Partial Dependence","what":"Partial Dependence Plots","title":"h3sdm workflow for multiple models","text":"create partial dependence plots (PDPs) visualize relationship key predictors predicted habitat suitability. PDPs show predicted outcome changes single predictor varies, averaging effects predictors. Now can plot PDPs.  predictors show positive relationship habitat suitability, Bio12 (annual precipitation) Bio1 (mean annual temperature) stand higher importance stronger positive effects. contrast, Bio15 (precipitation seasonality) weaker positive effect, suggesting areas variable rainfall somewhat suitable, less influential Bio12 Bio1.","code":"pdp_glm <- partial_dependence(e, variables = c(\"bio12\", \"bio1\", \"bio15\")) plot(pdp_glm)"},{"path":"https://manuelspinola.github.io/h3sdm/articles/multi_model_workflow.html","id":"conclusions","dir":"Articles","previous_headings":"","what":"14. Conclusions","title":"h3sdm workflow for multiple models","text":"tutorial demonstrated complete SDM workflow multiple models using h3sdm package. key steps included: Defining study area Loading preparing environmental predictors Fetching species occurrence data Building several predictive models spatial cross-validation Evaluating performance makingpredictions Assessing variable importance workflow demonstrates modeling single species using one model.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Manuel Spínola. Author, maintainer.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Spínola M (2025). h3sdm: Species Distribution Modeling H3 Grids. R package version 0.1.0, https://github.com/ManuelSpinola/h3sdm.","code":"@Manual{,   title = {h3sdm: Species Distribution Modeling with H3 Grids},   author = {Manuel Spínola},   year = {2025},   note = {R package version 0.1.0},   url = {https://github.com/ManuelSpinola/h3sdm}, }"},{"path":"https://manuelspinola.github.io/h3sdm/index.html","id":"h3sdm","dir":"","previous_headings":"","what":"Species Distribution Modeling with H3 Grids","title":"Species Distribution Modeling with H3 Grids","text":"h3sdm: Machine learning–based spatial species distribution modeling habitat/landscape analysis using H3 spatial index grids.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Species Distribution Modeling with H3 Grids","text":"h3sdm R package species distribution modeling (SDM) habitat analysis using hexagonal spatial index grids based H3. provides consistent spatial framework combine species occurrence data environmental predictors landscape metrics, enabling ecological modeling habitat characterization. modeling framework built tidymodels, offering flexibility use different approaches (e.g., logistic regression, GAMs, Random Forest, XGBoost). Key features include: Conversion point occurrence data H3-based spatial grids Extraction environmental landscape predictors different resolutions Support multiple modeling approaches tidymodels Tools visualizing model predictions habitat structure leveraging H3 grids tidymodels ecosystem, h3sdm makes easy bridge species distribution modeling landscape ecology scalable way.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Species Distribution Modeling with H3 Grids","text":"can install development version h3sdm GitHub using one following methods:","code":"# install.packages(\"pak\") pak::pak(\"ManuelSpinola/h3sdm\") # install.packages(\"remotes\") remotes::install_github(\"ManuelSpinola/h3sdm\") # install.packages(\"devtools\") devtools::install_github(\"ManuelSpinola/h3sdm\")"},{"path":"https://manuelspinola.github.io/h3sdm/index.html","id":"get-started","dir":"","previous_headings":"","what":"Get Started","title":"Species Distribution Modeling with H3 Grids","text":"Explore h3sdm Get Started section website, provides quick introduction package core workflows. practical examples, visit Articles section, vignette demonstrates different aspects species distribution habitat analysis using H3 grids.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/bioclim_current.html","id":null,"dir":"Reference","previous_headings":"","what":"Current bioclimatic raster — bioclim_current","title":"Current bioclimatic raster — bioclim_current","text":"GeoTIFF current bioclimatic variables Costa Rica.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/bioclim_current.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Current bioclimatic raster — bioclim_current","text":"GeoTIFF file, readable terra::rast().","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/bioclim_current.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Current bioclimatic raster — bioclim_current","text":"file stored inst/extdata/ can accessed : terra::rast(system.file(\"extdata\", \"bioclim_current.tif\", package = \"h3sdm\"))","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/bioclim_current.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Current bioclimatic raster — bioclim_current","text":"","code":"library(terra) #> terra 1.8.70 bio <- terra::rast(system.file(\"extdata\", \"bioclim_current.tif\", package = \"h3sdm\"))"},{"path":"https://manuelspinola.github.io/h3sdm/reference/bioclim_future.html","id":null,"dir":"Reference","previous_headings":"","what":"Future bioclimatic raster — bioclim_future","title":"Future bioclimatic raster — bioclim_future","text":"GeoTIFF projected bioclimatic variables Costa Rica.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/bioclim_future.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Future bioclimatic raster — bioclim_future","text":"GeoTIFF file, readable terra::rast().","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/bioclim_future.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Future bioclimatic raster — bioclim_future","text":"dataset corresponds climate projection: Model: INM-CM4-8 Scenario: SSP1-2.6 Period: 2021–2040 file stored inst/extdata/ can accessed : terra::rast(system.file(\"extdata\", \"bioclim_future.tif\", package = \"h3sdm\"))","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/bioclim_future.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Future bioclimatic raster — bioclim_future","text":"","code":"library(terra) bio <- terra::rast(system.file(\"extdata\", \"bioclim_future.tif\", package = \"h3sdm\"))"},{"path":"https://manuelspinola.github.io/h3sdm/reference/cr_outline_c.html","id":null,"dir":"Reference","previous_headings":"","what":"Costa Rica Continental Outline — cr_outline_c","title":"Costa Rica Continental Outline — cr_outline_c","text":"simplified outline Costa Rica sf object.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/cr_outline_c.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Costa Rica Continental Outline — cr_outline_c","text":"","code":"cr_outline_c"},{"path":"https://manuelspinola.github.io/h3sdm/reference/cr_outline_c.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"Costa Rica Continental Outline — cr_outline_c","text":"sf object containing polygon geometry Costa Rica.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/cr_outline_c.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"Costa Rica Continental Outline — cr_outline_c","text":"Adapted publicly available geographic data.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/cr_outline_c.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Costa Rica Continental Outline — cr_outline_c","text":"","code":"library(sf) #> Linking to GEOS 3.13.0, GDAL 3.8.5, PROJ 9.5.1; sf_use_s2() is TRUE plot(cr_outline_c)"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_calculate_it_metrics.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Information Theory Landscape Metrics for Hexagonal Grid — h3sdm_calculate_it_metrics","title":"Calculate Information Theory Landscape Metrics for Hexagonal Grid — h3sdm_calculate_it_metrics","text":"Calculates 5 Information Theory ()-based landscape metrics (condent, ent, joinent, mutinf, relmutinf) hexagon given H3 hexagonal grid.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_calculate_it_metrics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Information Theory Landscape Metrics for Hexagonal Grid — h3sdm_calculate_it_metrics","text":"","code":"h3sdm_calculate_it_metrics(landscape_raster, sf_grid)"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_calculate_it_metrics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Information Theory Landscape Metrics for Hexagonal Grid — h3sdm_calculate_it_metrics","text":"landscape_raster categorical SpatRaster containing land-cover data. sf_grid sf object containing hexagonal grid species land-cover data.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_calculate_it_metrics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Information Theory Landscape Metrics for Hexagonal Grid — h3sdm_calculate_it_metrics","text":"sf object containing input hex grid new columns calculated metric.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_calculate_it_metrics.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate Information Theory Landscape Metrics for Hexagonal Grid — h3sdm_calculate_it_metrics","text":"function computes landscape metrics using landscapemetrics::sample_lsm() workflow. results pivoted wide format easy use.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_calculate_it_metrics.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate Information Theory Landscape Metrics for Hexagonal Grid — h3sdm_calculate_it_metrics","text":"Hesselbarth et al., 2019. landscapemetrics: open-source R tool calculate landscape metrics. Ecography 42: 1648–1657. Nowosad & Stepinski, 2019. Information theory consistent framework landscape patterns. https://doi.org/10.1007/s10980-019-00830-x","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_calculate_it_metrics.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Information Theory Landscape Metrics for Hexagonal Grid — h3sdm_calculate_it_metrics","text":"","code":"# \\donttest{ # Assuming 'sf_grid' is an sf object with hexagons # result_sf <- h3sdm_calculate_it_metrics(sf_grid) # head(result_sf) # }"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_classify.html","id":null,"dir":"Reference","previous_headings":"","what":"Classify predictions based on an optimal threshold — h3sdm_classify","title":"Classify predictions based on an optimal threshold — h3sdm_classify","text":"Converts continuous probability predictions binary presence/absence based specified threshold.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_classify.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Classify predictions based on an optimal threshold — h3sdm_classify","text":"","code":"h3sdm_classify(predictions_sf, threshold)"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_classify.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Classify predictions based on an optimal threshold — h3sdm_classify","text":"predictions_sf sf object containing numeric column named prediction, typically produced h3sdm_predict(). threshold numeric value representing probability threshold (e.g., 0.45) predictions classified presence (1).","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_classify.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Classify predictions based on an optimal threshold — h3sdm_classify","text":"sf object geometry original columns, plus new integer column predicted_presence values 0 (absence) 1 (presence).","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_classify.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Classify predictions based on an optimal threshold — h3sdm_classify","text":"function useful converting continuous probability outputs binary presence/absence data mapping model evaluation purposes.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_classify.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Classify predictions based on an optimal threshold — h3sdm_classify","text":"","code":"if (FALSE) { # \\dontrun{ library(sf) library(dplyr)  # Crear un sf de ejemplo df <- data.frame(   id = 1:5,   prediction = c(0.2, 0.6, 0.45, 0.8, 0.3),   lon = c(-75, -74, -73, -72, -71),   lat = c(10, 11, 12, 13, 14) )  df_sf <- st_as_sf(df, coords = c(\"lon\", \"lat\"), crs = 4326)  # Clasificar usando un umbral classified_sf <- h3sdm_classify(df_sf, threshold = 0.5)  # Revisar resultados print(classified_sf) } # }"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_compare_models.html","id":null,"dir":"Reference","previous_headings":"","what":"Compare multiple H3SDM species distribution models — h3sdm_compare_models","title":"Compare multiple H3SDM species distribution models — h3sdm_compare_models","text":"Computes combines performance metrics multiple species distribution models created h3sdm_fit_models() similar workflows. Metrics include standard yardstick metrics (ROC AUC, TSS, Boyce index, etc.). Returns tibble summarizing model performance.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_compare_models.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compare multiple H3SDM species distribution models — h3sdm_compare_models","text":"","code":"h3sdm_compare_models(h3sdm_results)"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_compare_models.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compare multiple H3SDM species distribution models — h3sdm_compare_models","text":"h3sdm_results list workflow set containing fitted models metrics tibble. Typically, object output h3sdm_fit_models().","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_compare_models.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compare multiple H3SDM species distribution models — h3sdm_compare_models","text":"tibble one row per model per metric, containing: model Model name .metric Metric name (ROC AUC, TSS, Boyce, etc.) .estimator Metric type (usually \"binary\") mean Metric value","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_compare_models.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compare multiple H3SDM species distribution models — h3sdm_compare_models","text":"","code":"# \\donttest{ # Minimal reproducible example example_metrics <- tibble::tibble(   model = c(\"model1\", \"model2\"),   .metric = c(\"roc_auc\", \"tss_max\"),   .estimator = c(\"binary\", \"binary\"),   mean = c(0.85, 0.7) ) example_results <- list(metrics = example_metrics) h3sdm_compare_models(example_results) #> # A tibble: 1 × 4 #>   model  .metric .estimator  mean #>   <chr>  <chr>   <chr>      <dbl> #> 1 model1 roc_auc binary      0.85 # }"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Combine species and environmental data for SDMs using H3 grids — h3sdm_data","title":"Combine species and environmental data for SDMs using H3 grids — h3sdm_data","text":"Combines species presence–absence data environmental predictors. also calculates centroid coordinates (x y) hexagon grid cell.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combine species and environmental data for SDMs using H3 grids — h3sdm_data","text":"","code":"h3sdm_data(pa_sf, predictors_sf)"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combine species and environmental data for SDMs using H3 grids — h3sdm_data","text":"pa_sf sf object h3sdm_pa() containing species presence–absence data. predictors_sf sf object h3sdm_predictors() containing environmental predictors.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_data.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Combine species and environmental data for SDMs using H3 grids — h3sdm_data","text":"sf object containing species presence–absence, environmental predictor variables, centroid coordinates hexagon cell.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_data.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Combine species and environmental data for SDMs using H3 grids — h3sdm_data","text":"","code":"if (FALSE) { # \\dontrun{ my_species_pa <- h3sdm_pa(\"Panthera onca\", res = 6) my_predictors <- h3sdm_predictors(my_species_pa) combined_data <- h3sdm_data(my_species_pa, my_predictors) } # }"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_eval_metrics.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluate performance metrics for a fitted H3SDM model — h3sdm_eval_metrics","title":"Evaluate performance metrics for a fitted H3SDM model — h3sdm_eval_metrics","text":"Computes set performance metrics single fitted species distribution model. Includes standard yardstick metrics ROC AUC, accuracy, sensitivity, specificity, F1-score, Kappa, well ecological metrics True Skill Statistic (TSS) Boyce index. function designed helper evaluating models produced h3sdm_fit_model h3sdm_fit_models.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_eval_metrics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluate performance metrics for a fitted H3SDM model — h3sdm_eval_metrics","text":"","code":"h3sdm_eval_metrics(   fitted_model,   presence_data = NULL,   truth_col = \"presence\",   pred_col = \".pred_1\" )"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_eval_metrics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluate performance metrics for a fitted H3SDM model — h3sdm_eval_metrics","text":"fitted_model fitted model object, typically output h3sdm_fit_model(). presence_data Optional. sf object tibble containing presence locations used compute Boyce index. provided, Boyce index calculated. truth_col Character. Name column containing true presence/absence values (default \"presence\"). pred_col Character. Name column containing predicted probabilities (default \".pred_1\").","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_eval_metrics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Evaluate performance metrics for a fitted H3SDM model — h3sdm_eval_metrics","text":"tibble one row per metric, containing: .metric Metric name (e.g., \"roc_auc\", \"tss\", \"boyce\"). .estimator Estimator type (usually \"binary\"). mean Metric value. std_err Standard error (NA TSS Boyce). conf_low Lower bound 95% confidence interval (NA TSS Boyce). conf_high Upper bound 95% confidence interval (NA TSS Boyce).","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_eval_metrics.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluate performance metrics for a fitted H3SDM model — h3sdm_eval_metrics","text":"function centralizes model evaluation single fitted H3SDM model, combining general classification metrics ecological indices. especially useful systematically comparing model performance across species modeling approaches.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_eval_metrics.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluate performance metrics for a fitted H3SDM model — h3sdm_eval_metrics","text":"","code":"if (FALSE) { # \\dontrun{ # Assuming 'fitted' is the result of h3sdm_fit_model() metrics <- h3sdm_eval_metrics(   fitted_model = fitted,   presence_data = presence_sf,   truth_col = \"presence\",   pred_col = \".pred_1\" ) print(metrics) } # }"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_explain.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a DALEX explainer for h3sdm workflows — h3sdm_explain","title":"Create a DALEX explainer for h3sdm workflows — h3sdm_explain","text":"Creates DALEX explainer species distribution model fitted h3sdm_fit_model(). Prepares response predictor variables, ensuring columns used model training (including h3_address coordinates) included. explainer can used feature importance, model residuals, DALEX diagnostics.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_explain.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a DALEX explainer for h3sdm workflows — h3sdm_explain","text":"","code":"h3sdm_explain(model, data, response = \"presence\", label = \"h3sdm workflow\")"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_explain.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a DALEX explainer for h3sdm workflows — h3sdm_explain","text":"model fitted workflow returned h3sdm_fit_model(). data data.frame sf object containing original predictors response variable. sf object, geometry dropped automatically. response Character string specifying name response column. Must binary factor numeric vector (0/1). Defaults \"presence\". label Character string specifying label explainer. Defaults \"h3sdm workflow\".","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_explain.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a DALEX explainer for h3sdm workflows — h3sdm_explain","text":"object class explainer DALEX package, ready used feature_importance(), model_performance(), predict_parts(), DALEX functions.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_explain.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a DALEX explainer for h3sdm workflows — h3sdm_explain","text":"","code":"# \\donttest{ library(h3sdm) library(DALEX) #> Welcome to DALEX (version: 2.5.3). #> Find examples and detailed introduction at: http://ema.drwhy.ai/ library(parsnip)  dat <- data.frame(   x1 = rnorm(20),   x2 = rnorm(20),   presence = factor(sample(0:1, 20, replace = TRUE)) )  model <- logistic_reg() |>   fit(presence ~ x1 + x2, data = dat)  explainer <- h3sdm_explain(model, data = dat, response = \"presence\") #> Preparation of a new explainer is initiated #>   -> model label       :  h3sdm workflow  #>   -> data              :  20  rows  2  cols  #>   -> target variable   :  20  values  #>   -> predict function  :  custom_predict  #>   -> predicted values  :  No value for predict function target column. (  default  ) #>   -> model_info        :  package parsnip , ver. 1.3.3 , task classification (  default  )  #>   -> predicted values  :  numerical, min =  0.2165252 , mean =  0.5 , max =  0.7312219   #>   -> residual function :  difference between y and yhat (  default  ) #>   -> residuals         :  numerical, min =  -0.6924869 , mean =  -1.839084e-14 , max =  0.5992426   #>   A new explainer has been created!   feature_importance(explainer) #>       variable mean_dropout_loss          label #> 1 _full_model_             0.390 h3sdm workflow #> 2           x1             0.406 h3sdm workflow #> 3           x2             0.554 h3sdm workflow #> 4   _baseline_             0.480 h3sdm workflow # }"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_extract_cat.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate Area Proportions for Categorical Raster Classes — h3sdm_extract_cat","title":"Calculate Area Proportions for Categorical Raster Classes — h3sdm_extract_cat","text":"Extracts calculates area proportion land-use/land-cover (LULC) category found within input polygon sf_hex_grid. function tailored categorical rasters ensures accurate, sub-pixel weighted statistics.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_extract_cat.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate Area Proportions for Categorical Raster Classes — h3sdm_extract_cat","text":"","code":"h3sdm_extract_cat(spat_raster_cat, sf_hex_grid, proportion = TRUE)"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_extract_cat.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate Area Proportions for Categorical Raster Classes — h3sdm_extract_cat","text":"spat_raster_cat single-layer SpatRaster object containing categorical values (e.g., LULC classes). sf_hex_grid sf object containing polygonal geometries (e.g., H3 hexagons). Must contain column named h3_address joining grouping. proportion Logical. TRUE (default), output values proportion polygon area covered category (summing 1 covered area). FALSE, output raw sum coverage fraction (area).","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_extract_cat.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate Area Proportions for Categorical Raster Classes — h3sdm_extract_cat","text":"sf object identical sf_hex_grid, new columns appended categorical value found raster. Column names follow pattern <layer_name>_prop_<category_value>. Columns numerically ordered category value.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_extract_cat.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculate Area Proportions for Categorical Raster Classes — h3sdm_extract_cat","text":"function uses custom function exactextractr::exact_extract perform three critical steps: Filtering NA/NaN: Raster cells missing values (NA) explicitly excluded calculation, preventing creation _prop_NaN column. Area Consolidation: sums coverage fractions fragments belonging category within hexagon, essential polygons clipped fragmented. Numerical Ordering: final columns explicitly sorted based numerical value category (e.g., _prop_70 appears _prop_80) correct default alphanumeric sorting behavior tidyr::pivot_wider.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_extract_cat.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate Area Proportions for Categorical Raster Classes — h3sdm_extract_cat","text":"","code":"if (FALSE) { # \\dontrun{ # Assuming 'lulc' is a categorical SpatRaster and 'h7' is an sf hexagon grid # lulc_p <- h3sdm_extract_cat(lulc, h7, proportion = TRUE) # head(lulc_p) } # }"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_extract_num.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Area-Weighted Mean from Numeric Raster Stack — h3sdm_extract_num","title":"Extract Area-Weighted Mean from Numeric Raster Stack — h3sdm_extract_num","text":"Calculates area-weighted mean value layer numeric SpatRaster (single layer) within polygon feature sf object. function designed efficiently summarize continuous environmental variables (bioclimatic data) predefined spatial units (e.g., H3 hexagons). utilizes exactextractr ensure highly precise zonal statistics accounting sub-pixel coverage fractions.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_extract_num.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Area-Weighted Mean from Numeric Raster Stack — h3sdm_extract_num","text":"","code":"h3sdm_extract_num(spat_raster_multi, sf_hex_grid)"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_extract_num.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Area-Weighted Mean from Numeric Raster Stack — h3sdm_extract_num","text":"spat_raster_multi SpatRaster object terra package. Must contain numeric layers (can single layer stack/brick). sf_hex_grid sf object containing polygonal geometries (e.g., H3 hexagons). Must valid set polygons extraction.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_extract_num.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Area-Weighted Mean from Numeric Raster Stack — h3sdm_extract_num","text":"sf object identical sf_hex_grid, new columns appended. new column names match original SpatRaster layer names. values represent area-weighted mean variable within polygon.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_extract_num.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extract Area-Weighted Mean from Numeric Raster Stack — h3sdm_extract_num","text":"function relies exactextractr::exact_extract fun = \"weighted_mean\" weights = \"area\". methodology crucial maintaining spatial accuracy polygons irregular small relative raster resolution. critical check (nrow match) performed binding columns ensure data integrity prevent misalignment errors.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_extract_num.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Area-Weighted Mean from Numeric Raster Stack — h3sdm_extract_num","text":"","code":"if (FALSE) { # \\dontrun{ # Assuming 'bio' is a SpatRaster stack and 'h7' is an sf hexagon grid # bio_p <- h3sdm_extract_num(bio, h7) # head(bio_p) } # }"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_fit_model.html","id":null,"dir":"Reference","previous_headings":"","what":"Fits an SDM workflow to data using resampling and prepares it for stacking. — h3sdm_fit_model","title":"Fits an SDM workflow to data using resampling and prepares it for stacking. — h3sdm_fit_model","text":"Fits Species Distribution Model (SDM) workflow resampling data (cross-validation). function main training step optionally configures results used 'stacks' package.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_fit_model.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fits an SDM workflow to data using resampling and prepares it for stacking. — h3sdm_fit_model","text":"","code":"h3sdm_fit_model(   workflow,   data_split,   presence_data = NULL,   truth_col = \"presence\",   pred_col = \".pred_1\",   for_stacking = FALSE,   ... )"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_fit_model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fits an SDM workflow to data using resampling and prepares it for stacking. — h3sdm_fit_model","text":"workflow 'workflow' object tidymodels (e.g., GAM Random Forest). data_split 'rsplit' 'rset' object (e.g., result vfold_cv spatial_block_cv). presence_data (Optional) Original presence data (used extended metrics). truth_col Column name response variable (defaults \"presence\"). pred_col Column name prediction class interest (defaults \".pred_1\"). for_stacking Logical. TRUE, uses control_stack_resamples() save workflow information required 'stacks' package. FALSE, uses standard control save_pred = TRUE. ... Arguments passed functions (e.g., tune::fit_resamples needed).","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_fit_model.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fits an SDM workflow to data using resampling and prepares it for stacking. — h3sdm_fit_model","text":"list three elements: cv_model: result fit_resamples(). final_model: model fitted entire training set (first split). metrics: Extended evaluation metrics (presence_data provided).","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_fit_models.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit and evaluate multiple H3SDM species distribution models — h3sdm_fit_models","title":"Fit and evaluate multiple H3SDM species distribution models — h3sdm_fit_models","text":"Fits one species distribution models using tidymodels workflows specified resampling scheme, computes standard metrics (ROC AUC, accuracy, sensitivity, specificity, F1-score, Kappa) along TSS (True Skill Statistic) Boyce index model evaluation. Returns fitted models comparative metrics table.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_fit_models.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit and evaluate multiple H3SDM species distribution models — h3sdm_fit_models","text":"","code":"h3sdm_fit_models(   workflows,   data_split,   presence_data = NULL,   truth_col = \"presence\",   pred_col = \".pred_1\" )"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_fit_models.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit and evaluate multiple H3SDM species distribution models — h3sdm_fit_models","text":"workflows named list tidymodels workflows created h3sdm_workflow() manually. data_split resampling object (e.g., vfold_cv() h3sdm_spatial_cv()) cross-validation. presence_data sf object tibble presence locations compute Boyce index (optional). truth_col Character. Name column containing true presence/absence values (default \"presence\"). pred_col Character. Name column containing predicted probabilities (default \".pred_1\").","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_fit_models.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit and evaluate multiple H3SDM species distribution models — h3sdm_fit_models","text":"list two elements: models list fitted models returned h3sdm_fit_model(). metrics tibble one row per model per metric, including standard yardstick metrics, TSS, Boyce index.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_fit_models.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit and evaluate multiple H3SDM species distribution models — h3sdm_fit_models","text":"","code":"if (FALSE) { # \\dontrun{ # Example requires prepared recipes and resampling objects mod_log <- logistic_reg() %>%   set_engine(\"glm\") %>%   set_mode(\"classification\")  mod_rf <- rand_forest() %>%   set_engine(\"ranger\") %>%   set_mode(\"classification\")  workflows_list <- list(   logistic = h3sdm_workflow(mod_log, my_recipe),   rf       = h3sdm_workflow(mod_rf, my_recipe) )  results <- h3sdm_fit_models(   workflows     = workflows_list,   data_split    = my_cv_folds,   presence_data = presence_sf ) metrics_table <- results$metrics } # }"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_fit_models_stack.html","id":null,"dir":"Reference","previous_headings":"","what":"Fit multiple workflows for model stacking — h3sdm_fit_models_stack","title":"Fit multiple workflows for model stacking — h3sdm_fit_models_stack","text":"Fits set tidymodels workflows using resampling fit_resamples() control_stack_resamples() generate objects suitable stacking. workflow, resampled model (cv_model) original workflow returned. intended helper function creating ensembles multiple models h3sdm workflow.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_fit_models_stack.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fit multiple workflows for model stacking — h3sdm_fit_models_stack","text":"","code":"h3sdm_fit_models_stack(workflows, data_split, presence_data = NULL)"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_fit_models_stack.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fit multiple workflows for model stacking — h3sdm_fit_models_stack","text":"workflows named list tidymodels workflows. element workflow object. data_split resampling object, e.g., generated rsample::vfold_cv(). presence_data (Optional) data frame containing data fit workflows .","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_fit_models_stack.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fit multiple workflows for model stacking — h3sdm_fit_models_stack","text":"list one element models. element models list : cv_model: resampled model (tune_results object) workflow: original workflow object","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_fit_models_stack.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fit multiple workflows for model stacking — h3sdm_fit_models_stack","text":"Fit multiple workflows resampling stacking","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_fit_models_stack.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Fit multiple workflows for model stacking — h3sdm_fit_models_stack","text":"","code":"if (FALSE) { # \\dontrun{ # Example requires prepared workflows and resampling object: # wfs <- list(random_forest = my_workflow_rf, glmnet = my_workflow_glm) # scv <- rsample::vfold_cv(my_data, v = 5) results <- h3sdm_fit_models_stack(workflows = wfs, data_split = scv) results$models$random_forest$cv_model results$models$random_forest$workflow } # }"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_get_grid.html","id":null,"dir":"Reference","previous_headings":"","what":"Generar cuadrícula H3 para un área de interés — h3sdm_get_grid","title":"Generar cuadrícula H3 para un área de interés — h3sdm_get_grid","text":"Crea una cuadrícula de hexágonos H3 que cubre un área de interés (sf_object), asegurando que las celdas se ajusten la extensión del área y se recorten opcionalmente al contorno del AOI. Esta función es equivalente la usada en los módulos de paisaje de h3sdm, pero con el nombre estandarizado para mantener consistencia en el paquete.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_get_grid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generar cuadrícula H3 para un área de interés — h3sdm_get_grid","text":"","code":"h3sdm_get_grid(sf_object, res = 6, expand_factor = 0.1, clip_to_aoi = TRUE)"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_get_grid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generar cuadrícula H3 para un área de interés — h3sdm_get_grid","text":"sf_object Objeto sf que define el área de interés (AOI). res Entero entre 1 y 16. Define la resolución del índice H3. Valores mayores producen hexágonos más pequeños. expand_factor Valor numérico que amplía ligeramente el bounding box del AOI antes de generar los hexágonos. Por defecto 0.1. clip_to_aoi Lógico (TRUE o FALSE), indica si los hexágonos deben recortarse exactamente al contorno del AOI. Por defecto TRUE.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_get_grid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generar cuadrícula H3 para un área de interés — h3sdm_get_grid","text":"Un objeto sf con los hexágonos H3 correspondientes al área de interés, con geometrías válidas (MULTIPOLYGON).","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_get_grid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generar cuadrícula H3 para un área de interés — h3sdm_get_grid","text":"","code":"if (FALSE) { # \\dontrun{ library(sf)  # Crear un polígono de ejemplo cr <- st_as_sf(data.frame(   lon = c(-85, -85, -83, -83, -85),   lat = c(9, 11, 11, 9, 9) ), coords = c(\"lon\", \"lat\"), crs = 4326) |>   summarise(geometry = st_combine(geometry)) |>   st_cast(\"POLYGON\")  # Generar cuadrícula H3 h5 <- h3sdm_get_grid(cr, res = 5) plot(st_geometry(h5)) } # }"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_get_records.html","id":null,"dir":"Reference","previous_headings":"","what":"Query Species Occurrence Records within an H3 Area of Interest (AOI) — h3sdm_get_records","title":"Query Species Occurrence Records within an H3 Area of Interest (AOI) — h3sdm_get_records","text":"Downloads species occurrence records providers (e.g., GBIF) using spocc package, filtering initial query exact polygonal boundary Area Interest (AOI) maximum efficiency precision.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_get_records.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Query Species Occurrence Records within an H3 Area of Interest (AOI) — h3sdm_get_records","text":"","code":"h3sdm_get_records(   species,   aoi_sf,   providers = NULL,   limit = 500,   remove_duplicates = FALSE,   date = NULL )"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_get_records.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Query Species Occurrence Records within an H3 Area of Interest (AOI) — h3sdm_get_records","text":"species Character string specifying species name query (e.g., \"Puma concolor\"). aoi_sf sf object defining Area Interest (AOI). CRS transformed WGS84 (EPSG:4326) query. providers Character vector data providers query (e.g., \"gbif\", \"bison\"). NULL (default), available providers used. limit Numeric. maximum number records retrieve per provider. Default 500. remove_duplicates Logical. TRUE, records identical longitude latitude removed using dplyr::distinct(). Default FALSE. date Character vector specifying date range (e.g., c('2000-01-01', '2020-12-31')).","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_get_records.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Query Species Occurrence Records within an H3 Area of Interest (AOI) — h3sdm_get_records","text":"sf object points containing filtered occurrence records, geometry confirmed fall strictly within aoi_sf boundary. records found download fails, empty sf object expected structure returned.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_get_records.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Query Species Occurrence Records within an H3 Area of Interest (AOI) — h3sdm_get_records","text":"function transforms aoi_sf polygon WKT string, used spocc::occ geometry argument efficient WKT-based querying. Final spatial filtering performed using sf::st_intersection ensure strict containment. critical check included prevent errors API returns data (addressing 'column found' error).","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_get_records.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Query Species Occurrence Records within an H3 Area of Interest (AOI) — h3sdm_get_records","text":"","code":"if (FALSE) { # \\dontrun{ # Assuming aoi_sf is a valid sf polygon # h3_records <- h3sdm_get_records(\"Puma concolor\", aoi_sf, providers = \"gbif\", limit = 1000) # head(h3_records) } # }"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_get_records_by_hexagon.html","id":null,"dir":"Reference","previous_headings":"","what":"Download Species Records and Count Occurrences per H3 Hexagon — h3sdm_get_records_by_hexagon","title":"Download Species Records and Count Occurrences per H3 Hexagon — h3sdm_get_records_by_hexagon","text":"function downloads occurrence records one species counts number records falling inside H3 hexagon covering specified Area Interest (AOI).","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_get_records_by_hexagon.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Download Species Records and Count Occurrences per H3 Hexagon — h3sdm_get_records_by_hexagon","text":"","code":"h3sdm_get_records_by_hexagon(   species,   aoi_sf,   res = 6,   providers = NULL,   remove_duplicates = FALSE,   date = NULL,   expand_factor = 0.1,   limit = 500 )"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_get_records_by_hexagon.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Download Species Records and Count Occurrences per H3 Hexagon — h3sdm_get_records_by_hexagon","text":"species Character vector species names query (e.g., c(\"Puma concolor\", \"Panthera onca\")). aoi_sf sf polygon defining Area Interest (AOI). res Numeric. H3 resolution level (default 6), determining hexagon size. providers Character vector data providers (e.g., \"gbif\"). NULL, providers used. remove_duplicates Logical. TRUE, duplicate coordinates removed counting. Default FALSE. date Character vector specifying date range (e.g., c('2000-01-01','2020-12-31')). expand_factor Numeric. Factor expand AOI bounding box generating H3 grid. Default 0.1. limit Numeric. Maximum number records retrieve per species per provider. Default 500.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_get_records_by_hexagon.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Download Species Records and Count Occurrences per H3 Hexagon — h3sdm_get_records_by_hexagon","text":"sf object containing H3 hexagonal grid (MULTIPOLYGON) additional integer columns species (spaces replaced underscores) showing count occurrence records hexagon. Hexagons records 0.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_get_records_by_hexagon.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Download Species Records and Count Occurrences per H3 Hexagon — h3sdm_get_records_by_hexagon","text":"Download Species Records Count Occurrences per H3 Hexagon species: H3 grid generated across AOI using h3sdm_get_grid(). Occurrence records downloaded using h3sdm_get_records(). Points joined hexagonal grid sf::st_join(). Counts points per hexagon calculated. Counts merged main hex grid. function ensures column names derived species names safe R replacing spaces underscores handles API failures gracefully.","code":""},{"path":[]},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_get_records_by_hexagon.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Download Species Records and Count Occurrences per H3 Hexagon — h3sdm_get_records_by_hexagon","text":"","code":"if (FALSE) { # \\dontrun{ # Assuming aoi_sf is a valid sf polygon # species_list <- c(\"Agalychnis callidryas\", \"Smilisca baudinii\") # hex_counts <- h3sdm_get_records_by_hexagon(species_list, aoi_sf, res = 7, limit = 1000) # head(hex_counts) } # }"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_pa.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate presence/pseudo-absence dataset for a species — h3sdm_pa","title":"Generate presence/pseudo-absence dataset for a species — h3sdm_pa","text":"Generates hexagonal grid AOI, assigns species presence records hexagons, samples pseudo-absences hexagons records.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_pa.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate presence/pseudo-absence dataset for a species — h3sdm_pa","text":"","code":"h3sdm_pa(   species,   aoi_sf,   res = 6,   n_pseudoabs = 500,   providers = NULL,   remove_duplicates = FALSE,   date = NULL,   limit = 500,   expand_factor = 0.1 )"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_pa.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate presence/pseudo-absence dataset for a species — h3sdm_pa","text":"species character Species name (single string) records requested. aoi_sf sf AOI (area interest) polygon. res integer H3 resolution hexagonal grid. n_pseudoabs integer Number pseudo-absence hexagons sample. providers character Optional vector data providers (e.g., \"gbif\", \"inat\"). remove_duplicates logical Remove duplicate records coordinates. date character Optional date filter records. limit integer Maximum number records download. expand_factor numeric Factor expand AOI creating hex grid.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_pa.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate presence/pseudo-absence dataset for a species — h3sdm_pa","text":"sf object columns: h3_address: H3 index hexagon. presence: factor levels \"0\" (pseudo-absence) \"1\" (presence). geometry: MULTIPOLYGON hexagon.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_pa.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate presence/pseudo-absence dataset for a species — h3sdm_pa","text":"","code":"# \\donttest{ data(cr_outline_c, package = \"h3sdm\") dataset <- h3sdm_pa(\"Agalychnis callidryas\", cr_outline_c, res = 7, n_pseudoabs = 100) # }"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_predict.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict species presence probability using H3 hexagons — h3sdm_predict","title":"Predict species presence probability using H3 hexagons — h3sdm_predict","text":"Uses fitted tidymodels workflow (h3sdm_fit_model standalone workflow) predict species presence probabilities new spatial H3 grid. Automatically generates centroid coordinates (x y) missing. new_data must contain predictor variables used model training.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_predict.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict species presence probability using H3 hexagons — h3sdm_predict","text":"","code":"h3sdm_predict(fit_object, new_data)"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_predict.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict species presence probability using H3 hexagons — h3sdm_predict","text":"fit_object fitted tidymodels workflow output list h3sdm_fit_model. new_data sf object containing spatial grid predictor variables used model training.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_predict.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict species presence probability using H3 hexagons — h3sdm_predict","text":"sf object original geometry new column prediction containing predicted probability presence hexagon.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_predict.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predict species presence probability using H3 hexagons — h3sdm_predict","text":"","code":"if (FALSE) { # \\dontrun{ # Predict presence probabilities on a new hex grid predictions_sf <- h3sdm_predict(   fit_object = fitted_model,   new_data   = grid_sf ) } # }"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_predictors.html","id":null,"dir":"Reference","previous_headings":"","what":"Combine Predictor Data from Multiple sf Objects — h3sdm_predictors","title":"Combine Predictor Data from Multiple sf Objects — h3sdm_predictors","text":"function merges predictor variables multiple sf objects single sf object. preserves geometry first input (num_sf) joins columns sf objects using common key (h3_address ID).","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_predictors.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Combine Predictor Data from Multiple sf Objects — h3sdm_predictors","text":"","code":"h3sdm_predictors(...)"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_predictors.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Combine Predictor Data from Multiple sf Objects — h3sdm_predictors","text":"num_sf sf object containing numeric predictor variables. cat_sf sf object containing categorical predictor variables. it_sf sf object containing landscape information theory metrics.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_predictors.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Combine Predictor Data from Multiple sf Objects — h3sdm_predictors","text":"sf object containing geometry num_sf predictor columns num_sf, cat_sf, it_sf.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_predictors.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Combine Predictor Data from Multiple sf Objects — h3sdm_predictors","text":"function uses left join based h3_address column present, otherwise falls back ID. Geometries right-hand side sf objects dropped avoid conflicts, final geometry cast MULTIPOLYGON.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_predictors.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Combine Predictor Data from Multiple sf Objects — h3sdm_predictors","text":"","code":"# \\donttest{ # Assume you have 2 or more sf objects with predictor variables: # num_sf: numeric predictors # cat_sf: categorical predictors # it_sf: landscape or information metrics  # Combine them into a single sf object combined <- h3sdm_predictors(num_sf, cat_sf, it_sf) #> Error: object 'num_sf' not found  # Resulting object contains geometry from num_sf and all attribute columns head(combined) #> Error in h(simpleError(msg, call)): error in evaluating the argument 'x' in selecting a method for function 'head': object 'combined' not found # }"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_recipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a tidymodels recipe for H3-based SDMs — h3sdm_recipe","title":"Create a tidymodels recipe for H3-based SDMs — h3sdm_recipe","text":"Prepares sf object H3 hexagonal data modeling tidymodels ecosystem. Extracts centroid coordinates, assigns appropriate roles variables automatically, returns ready--use recipe modeling species distributions.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_recipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a tidymodels recipe for H3-based SDMs — h3sdm_recipe","text":"","code":"h3sdm_recipe(data)"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_recipe.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a tidymodels recipe for H3-based SDMs — h3sdm_recipe","text":"data sf object, typically output h3sdm_data(), including species presence-absence, H3 addresses, environmental predictors. geometry must type MULTIPOLYGON.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_recipe.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a tidymodels recipe for H3-based SDMs — h3sdm_recipe","text":"tidymodels recipe object (class \"h3sdm_recipe\") ready modeling.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_recipe.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a tidymodels recipe for H3-based SDMs — h3sdm_recipe","text":"function prepares spatial H3 grid data species distribution modeling: Extracts centroid coordinates (x y) MULTIPOLYGON geometries using sf functions. Removes geometry column create purely tabular dataset tidymodels. Assigns roles columns: presence → \"outcome\" (target variable) h3_address → \"id\" (used joining predictions later) x y → \"spatial_predictor\" columns assigned \"predictor\" role.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_recipe.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a tidymodels recipe for H3-based SDMs — h3sdm_recipe","text":"","code":"if (FALSE) { # \\dontrun{ # Example: Prepare H3 hexagonal SDM data for modeling # `combined_data` is typically the output of h3sdm_data() sdm_recipe <- h3sdm_recipe(combined_data) sdm_recipe  # inspect the recipe object } # }"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_recipe_gam.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a 'recipe' object for Generalized Additive Models (GAM) in SDM. — h3sdm_recipe_gam","title":"Creates a 'recipe' object for Generalized Additive Models (GAM) in SDM. — h3sdm_recipe_gam","text":"function prepares sf (Simple Features) object use Species Distribution Model (SDM) workflow 'mgcv' GAM engine within 'tidymodels' ecosystem. crucial step extracting coordinates (x, y) geometry assigning predictor role can used GAM's spatial smooth term (s(x, y, bs = \"tp\")). also assigns special roles 'presence' 'h3_address' variables.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_recipe_gam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a 'recipe' object for Generalized Additive Models (GAM) in SDM. — h3sdm_recipe_gam","text":"","code":"h3sdm_recipe_gam(data)"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_recipe_gam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a 'recipe' object for Generalized Additive Models (GAM) in SDM. — h3sdm_recipe_gam","text":"data sf (Simple Features) object containing species presence/absence/abundance data, environmental variables (e.g., bioclimatic), geometry (e.g., H3 centroids points).","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_recipe_gam.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates a 'recipe' object for Generalized Additive Models (GAM) in SDM. — h3sdm_recipe_gam","text":"recipe object class h3sdm_recipe_gam, ready chained additional preprocessing steps (e.g., normalization).","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_recipe_gam.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Creates a 'recipe' object for Generalized Additive Models (GAM) in SDM. — h3sdm_recipe_gam","text":"Assigned Roles: outcome: \"presence\" (column containing response variable). id: \"h3_address\" (cell identifier, used modeling). predictor: variables, including x y GAM's smoothing function. Note x y: x y coordinates added recipe's internal data frame defined predictor meet requirements mgcv engine.","code":""},{"path":[]},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_recipe_gam.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates a 'recipe' object for Generalized Additive Models (GAM) in SDM. — h3sdm_recipe_gam","text":"","code":"if (FALSE) { # \\dontrun{ # Assuming 'data_sf' is your sf object with 'presence' and 'h3_address' # gam_rec <- h3sdm_recipe_gam(data_sf) # Add normalization only to bio variables, excluding x and y # final_rec <- gam_rec %>% step_normalize(starts_with(\"bio\")) } # }"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_spatial_cv.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a spatial-aware cross-validation split for H3 data — h3sdm_spatial_cv","title":"Create a spatial-aware cross-validation split for H3 data — h3sdm_spatial_cv","text":"Generates spatially aware cross-validation split species distribution modeling using H3 hexagonal grids. helps avoid inflated model performance estimates caused spatial autocorrelation, producing robust model evaluation.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_spatial_cv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a spatial-aware cross-validation split for H3 data — h3sdm_spatial_cv","text":"","code":"h3sdm_spatial_cv(data, method = \"block\", v = 5, ...)"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_spatial_cv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a spatial-aware cross-validation split for H3 data — h3sdm_spatial_cv","text":"data sf object, typically output h3sdm_data(). method Character. spatial resampling method use: \"block\" Use spatialsample::spatial_block_cv() block-based spatial CV. \"cluster\" Use spatialsample::spatial_clustering_cv() cluster-based spatial CV. v Integer. Number folds (default = 5). ... Additional arguments passed underlying spatialsample function.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_spatial_cv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a spatial-aware cross-validation split for H3 data — h3sdm_spatial_cv","text":"rsplit object (rsample) representing spatial CV folds.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_spatial_cv.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a spatial-aware cross-validation split for H3 data — h3sdm_spatial_cv","text":"Spatial cross-validation avoids overly optimistic performance estimates ensuring training testing data spatially separated. \"block\": Divides spatial domain contiguous blocks. \"cluster\": Groups locations spatial clusters splitting.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_spatial_cv.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a spatial-aware cross-validation split for H3 data — h3sdm_spatial_cv","text":"","code":"if (FALSE) { # \\dontrun{ # Example: Create spatial cross-validation splits for H3 data  # Block spatial CV with default folds spatial_cv_block <- h3sdm_spatial_cv(combined_data, method = \"block\")  # Cluster spatial CV with 10 folds spatial_cv_cluster <- h3sdm_spatial_cv(combined_data, method = \"cluster\", v = 10) } # }"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_stack_fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates and fully fits an ensemble model (Stack). — h3sdm_stack_fit","title":"Creates and fully fits an ensemble model (Stack). — h3sdm_stack_fit","text":"function combines process creating model stack, optimizing weights (blend_predictions), fitting base models complete training set (fit_members()) single step. Warning: follow canonical tidymodels flow convenient. requires fitting results generated using h3sdm_fit_model(..., for_stacking = TRUE).","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_stack_fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates and fully fits an ensemble model (Stack). — h3sdm_stack_fit","text":"","code":"h3sdm_stack_fit(..., non_negative = TRUE, metric = NULL)"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_stack_fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates and fully fits an ensemble model (Stack). — h3sdm_stack_fit","text":"... List objects result h3sdm_fit_model(). object must contain cv_model element (result fit_resamples). non_negative Logical. TRUE (default), forces candidate model weights non-negative. metric metric used optimize combination weights.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_stack_fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates and fully fits an ensemble model (Stack). — h3sdm_stack_fit","text":"list containing two elements: blended_model (stack blending) final_model (fully fitted model_stack object). final_model ready direct prediction predict().","code":""},{"path":[]},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_utils.html","id":null,"dir":"Reference","previous_headings":"","what":"Utilities for CRAN checks — h3sdm_utils","title":"Utilities for CRAN checks — h3sdm_utils","text":"Imports global variable declarations avoid check NOTES.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_workflow.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a tidymodels workflow for H3-based SDMs — h3sdm_workflow","title":"Create a tidymodels workflow for H3-based SDMs — h3sdm_workflow","text":"Combines model specification prepared recipe single tidymodels workflow. workflow suitable species distribution modeling using H3 hexagonal grids can directly fitted cross-validated.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_workflow.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a tidymodels workflow for H3-based SDMs — h3sdm_workflow","text":"","code":"h3sdm_workflow(model_spec, recipe)"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_workflow.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a tidymodels workflow for H3-based SDMs — h3sdm_workflow","text":"model_spec tidymodels model specification (e.g., logistic_reg(), rand_forest(), boost_tree()), describing model type engine use fitting. recipe tidymodels recipe object, typically created h3sdm_recipe(), preprocesses data defines predictor/response roles.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_workflow.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a tidymodels workflow for H3-based SDMs — h3sdm_workflow","text":"workflow object ready used model fitting fit() cross-validation.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_workflow.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create a tidymodels workflow for H3-based SDMs — h3sdm_workflow","text":"function creates workflow combines preprocessing modeling steps. encapsulation allows consistent model training evaluation tidymodels functions like fit() fit_resamples(), particularly useful applying multiple models parallel.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_workflow.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a tidymodels workflow for H3-based SDMs — h3sdm_workflow","text":"","code":"if (FALSE) { # \\dontrun{ library(parsnip) # Example: Create a tidymodels workflow for H3-based species distribution modeling  # Step 1: Define model specification my_model_spec <- logistic_reg() %>%   set_mode(\"classification\") %>%   set_engine(\"glm\")  # Step 2: Create recipe my_recipe <- h3sdm_recipe(combined_data)  # Step 3: Combine into workflow sdm_wf <- h3sdm_workflow(model_spec = my_model_spec, sdm_recipe = my_recipe) } # }"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_workflow_gam.html","id":null,"dir":"Reference","previous_headings":"","what":"Creates a tidymodels workflow for Generalized Additive Models (GAM). — h3sdm_workflow_gam","title":"Creates a tidymodels workflow for Generalized Additive Models (GAM). — h3sdm_workflow_gam","text":"function constructs workflow object combining GAM model specification (gen_additive_mod mgcv engine) either recipe object explicit model formula. optimized Species Distribution Models (SDM) use smooth splines, ensuring specialized GAM formula (containing s() terms) correctly passed model, even recipe provided general data preprocessing.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_workflow_gam.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Creates a tidymodels workflow for Generalized Additive Models (GAM). — h3sdm_workflow_gam","text":"","code":"h3sdm_workflow_gam(gam_spec, recipe = NULL, formula = NULL)"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_workflow_gam.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Creates a tidymodels workflow for Generalized Additive Models (GAM). — h3sdm_workflow_gam","text":"gam_spec parsnip model specification type gen_additive_mod(), configured set_engine(\"mgcv\"). recipe (Optional) recipes package recipe object (e.g., output h3sdm_recipe_gam). Used general data preprocessing like normalization dummy variable creation. formula (Optional) formula object defines structure GAM, including smooth terms (e.g., y ~ s(x1) + s(x, y)). provided alongside recipe, formula overrides recipe's implicit formula final model fit.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_workflow_gam.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Creates a tidymodels workflow for Generalized Additive Models (GAM). — h3sdm_workflow_gam","text":"workflow object, ready fitting fit() resampling fit_resamples() tune_grid().","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_workflow_gam.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Creates a tidymodels workflow for Generalized Additive Models (GAM). — h3sdm_workflow_gam","text":"Formula Priority: recipe provided, workflow uses recipe's implicit formula (e.g., outcome ~ .). recipe formula provided, workflow uses recipe data preprocessing explicitly passes formula mgcv engine fitting, enabling use specialized terms like s(x, y).","code":""},{"path":[]},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_workflow_gam.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Creates a tidymodels workflow for Generalized Additive Models (GAM). — h3sdm_workflow_gam","text":"","code":"if (FALSE) { # \\dontrun{ library(parsnip) # 1. Define the model specification gam_spec <- gen_additive_mod() %>%   set_engine(\"mgcv\") %>%   set_mode(\"classification\")  # 2. Define a specialized GAM formula gam_formula <- presence ~ s(bio1) + s(x, y, bs = \"tp\")  # 3. Define a base recipe (assuming 'data' exists) # base_rec <- h3sdm_recipe_gam(data)  # 4. Create the combined workflow # h3sdm_wf <- h3sdm_workflow_gam( #   gam_spec = gam_spec, #   recipe = base_rec, #   formula = gam_formula # ) } # }"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_workflows.html","id":null,"dir":"Reference","previous_headings":"","what":"Create multiple tidymodels workflows for H3-based SDMs — h3sdm_workflows","title":"Create multiple tidymodels workflows for H3-based SDMs — h3sdm_workflows","text":"Creates list tidymodels workflows multiple model specifications prepared recipe. useful comparing different modeling approaches species distribution modeling using H3 hexagonal grids. returned workflows can used model fitting resampling.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_workflows.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create multiple tidymodels workflows for H3-based SDMs — h3sdm_workflows","text":"","code":"h3sdm_workflows(model_specs, recipe)"},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_workflows.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create multiple tidymodels workflows for H3-based SDMs — h3sdm_workflows","text":"model_specs named list tidymodels model specifications (e.g., logistic_reg(), rand_forest(), boost_tree()), element specifies different modeling approach included workflow set. recipe tidymodels recipe object, typically created h3sdm_recipe(), prepares preprocesses data modeling.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_workflows.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create multiple tidymodels workflows for H3-based SDMs — h3sdm_workflows","text":"named list workflow objects, one per model specification.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_workflows.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create multiple tidymodels workflows for H3-based SDMs — h3sdm_workflows","text":"function automates creation workflows multiple model specifications. workflow combines preprocessing steps (recipe) different modeling method. facilitates systematic comparison models especially useful ensemble stacking approaches.","code":""},{"path":"https://manuelspinola.github.io/h3sdm/reference/h3sdm_workflows.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create multiple tidymodels workflows for H3-based SDMs — h3sdm_workflows","text":"","code":"if (FALSE) { # \\dontrun{ # ... (examples are correct as is) ... } # }"},{"path":"https://manuelspinola.github.io/h3sdm/news/index.html","id":"h3sdm-010","dir":"Changelog","previous_headings":"","what":"h3sdm 0.1.0","title":"h3sdm 0.1.0","text":"Initial CRAN submission.","code":""}]
